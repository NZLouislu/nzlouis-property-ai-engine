{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nzlouislu/nzlouis-property-ai-engine/blob/main/notebooks/property_experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uEb6ngWtsCB"
      },
      "source": [
        "房产预测系统实验性Notebook - 改进版本\n",
        "\n",
        "此Notebook实现了分析报告中提到的改进功能：\n",
        "1. 在第一次运行时删除之前的预测数据\n",
        "2. 支持一次生成更多预测数据，如Wellington的所有数据"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBO3T8oVtsCF"
      },
      "source": [
        "第一步：安装依赖"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_fHAb8ItsCG"
      },
      "outputs": [],
      "source": [
        "# 安装所需的库\n",
        "!pip install supabase\n",
        "!pip install scikit-learn\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SFnsk7StsCH"
      },
      "source": [
        "第二步：导入库和创建Supabase客户端"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Czxik_1UtsCH"
      },
      "outputs": [],
      "source": [
        "# 导入所需的库\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from supabase import create_client, Client\n",
        "from dotenv import load_dotenv\n",
        "import sys\n",
        "import re\n",
        "from datetime import datetime\n",
        "import joblib\n",
        "\n",
        "# 添加项目根目录到Python路径\n",
        "sys.path.append('/content/nzlouis-property-ai-engine')\n",
        "\n",
        "# 尝试从项目配置中导入Supabase客户端创建函数\n",
        "try:\n",
        "    from config.supabase_config import create_supabase_client\n",
        "    print(\"成功从项目配置导入Supabase客户端创建函数\")\n",
        "except ImportError:\n",
        "    print(\"无法从项目配置导入Supabase客户端创建函数，将使用环境变量创建客户端\")\n",
        "    def create_supabase_client() -> Client:\n",
        "        SUPABASE_URL = os.getenv(\"SUPABASE_URL\")\n",
        "        SUPABASE_KEY = os.getenv(\"SUPABASE_KEY\")\n",
        "        if not SUPABASE_URL or not SUPABASE_KEY:\n",
        "            raise ValueError(\"SUPABASE_URL 和 SUPABASE_KEY 环境变量必须设置\")\n",
        "        return create_client(SUPABASE_URL, SUPABASE_KEY)\n",
        "\n",
        "# utils.py - 辅助函数\n",
        "import numpy as np\n",
        "\n",
        "def to_json_serializable(records):\n",
        "    \"\"\"\n",
        "    将 list[dict] 中的 numpy 数据类型转换为 Python 原生类型，\n",
        "    以便 json.dumps() 或 Supabase 客户端序列化不报错。\n",
        "    \"\"\"\n",
        "    new_recs = []\n",
        "    for rec in records:\n",
        "        new = {}\n",
        "        for k, v in rec.items():\n",
        "            if isinstance(v, np.integer):        # 包括 int64, int32…\n",
        "                new[k] = int(v)                  # 转为 Python int\n",
        "            elif isinstance(v, np.floating):     # 包括 float64, float32…\n",
        "                new[k] = float(v)                # 转为 Python float\n",
        "            else:\n",
        "                new[k] = v\n",
        "        new_recs.append(new)\n",
        "    return new_recs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpNjgK2FtsCI"
      },
      "source": [
        "第三步：定义数据获取函数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4QRV3_DtsCI"
      },
      "outputs": [],
      "source": [
        "def fetch_training_data():\n",
        "    \"\"\"\n",
        "    获取训练数据：从 properties_with_is_listed（status=1）和 properties_to_predict（status=0）视图中获取数据，并合并为训练集。\n",
        "    \"\"\"\n",
        "    print(\"开始获取训练数据...\")\n",
        "    client = create_supabase_client()\n",
        "    try:\n",
        "        # 获取 status=1 的房产数据\n",
        "        res_listed = (\n",
        "            client\n",
        "            .from_('properties_with_is_listed')\n",
        "            .select('*')\n",
        "            .execute()\n",
        "        )\n",
        "        df_listed = pd.DataFrame(res_listed.data) if res_listed.data else pd.DataFrame()\n",
        "\n",
        "        # 获取 status=0 的房产数据\n",
        "        res_unlisted = (\n",
        "            client\n",
        "            .from_('properties_to_predict')\n",
        "            .select('*')\n",
        "            .execute()\n",
        "        )\n",
        "        df_unlisted = pd.DataFrame(res_unlisted.data) if res_unlisted.data else pd.DataFrame()\n",
        "\n",
        "        # 合并两个数据集\n",
        "        df_combined = pd.concat([df_listed, df_unlisted], ignore_index=True)\n",
        "\n",
        "        if df_combined.empty:\n",
        "            print(\"警告: 没有获取到训练数据。\")\n",
        "            return None\n",
        "\n",
        "        print(f\"获取的训练数据列: {df_combined.columns.tolist()}\")\n",
        "        return df_combined\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"错误: 获取训练数据时发生错误: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def fetch_prediction_data(suburb_filter=None, city_filter=None):\n",
        "    \"\"\"\n",
        "    获取预测数据：查询 properties_to_predict 视图，\n",
        "    并可按 suburb 或 city 等条件过滤。\n",
        "    \n",
        "    参数:\n",
        "    suburb_filter: 区域过滤条件 (可选)\n",
        "    city_filter: 城市过滤条件 (可选)\n",
        "    \"\"\"\n",
        "    print(\"开始获取预测数据...\")\n",
        "    client = create_supabase_client()\n",
        "    try:\n",
        "        # 构建查询\n",
        "        query = client.from_('properties_to_predict').select('*')\n",
        "        \n",
        "        # 应用过滤条件\n",
        "        if suburb_filter:\n",
        "            query = query.eq('suburb', suburb_filter)\n",
        "        elif city_filter:\n",
        "            # 注意：这里假设数据库中有city字段，如果没有需要调整\n",
        "            query = query.eq('city', city_filter)\n",
        "            \n",
        "        res = query.execute()\n",
        "        \n",
        "        print(\"成功从 Supabase 获取预测数据\")\n",
        "        if res.data:\n",
        "            df = pd.DataFrame(res.data)\n",
        "            print(f\"获取的预测数据列: {df.columns.tolist()}\")\n",
        "            print(f\"获取的预测数据行数: {len(df)}\")\n",
        "            return df\n",
        "        else:\n",
        "            print(\"警告: 没有获取到需要预测的数据。\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"错误: 获取预测数据时发生错误: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def clear_previous_predictions():\n",
        "    \"\"\"\n",
        "    清除 property_status 表中的旧预测数据\n",
        "    \"\"\"\n",
        "    print(\"正在清空 property_status 表中的旧数据...\")\n",
        "    client = create_supabase_client()\n",
        "    \n",
        "    try:\n",
        "        # 删除所有记录\n",
        "        delete_result = client.table('property_status').delete().neq('id', 0).execute()\n",
        "        print(f\"已清空 property_status 表，共删除 {len(delete_result.data) if delete_result.data else 0} 条记录。\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"警告: 删除旧数据时发生错误 - {e}\")\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CF8pgy1tsCJ"
      },
      "source": [
        "第四步：数据预处理和模型训练"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xtAooTdtsCJ"
      },
      "outputs": [],
      "source": [
        "def extract_property_history_features(history_str):\n",
        "    \"\"\"\n",
        "    从 property_history 字段中提取有用的特征：\n",
        "    1. 交易次数\n",
        "    2. 最近一次交易距今的天数\n",
        "    3. 是否包含建造记录\n",
        "    \"\"\"\n",
        "    if pd.isnull(history_str) or not isinstance(history_str, str):\n",
        "        return 0, -1, 0\n",
        "\n",
        "    # 提取交易事件\n",
        "    events = history_str.split('; ')\n",
        "    transaction_count = len(events)\n",
        "\n",
        "    # 检查是否包含\"Property Built\"事件\n",
        "    has_built_event = int(any('Property Built' in event for event in events))\n",
        "\n",
        "    # 提取最近一次交易距今的天数\n",
        "    date_pattern = r'(\\d{4}-\\d{2}-\\d{2})'\n",
        "    dates = [re.search(date_pattern, event) for event in events]\n",
        "    dates = [pd.to_datetime(match.group(1)) for match in dates if match]\n",
        "\n",
        "    if dates:\n",
        "        most_recent_date = max(dates)\n",
        "        days_since_last_transaction = (pd.Timestamp.now() - most_recent_date).days\n",
        "    else:\n",
        "        days_since_last_transaction = -1  # 没有找到日期时使用默认值\n",
        "\n",
        "    return transaction_count, days_since_last_transaction, has_built_event\n",
        "\n",
        "\n",
        "def preprocess_data(df, for_prediction=False):\n",
        "    print(\"开始数据预处理...\")\n",
        "    feature_columns = ['year_built', 'bedrooms', 'bathrooms', 'car_spaces', 'floor_size',\n",
        "                       'land_area', 'last_sold_price', 'capital_value',\n",
        "                       'land_value', 'improvement_value', 'suburb',\n",
        "                       'has_rental_history', 'is_currently_rented', 'property_history']\n",
        "\n",
        "    # 确保所有需要的列都存在\n",
        "    for col in feature_columns:\n",
        "        if col not in df.columns:\n",
        "            df[col] = None\n",
        "\n",
        "    X = df[feature_columns].copy()\n",
        "\n",
        "    # 处理数值型特征\n",
        "    X['floor_size'] = pd.to_numeric(X['floor_size'].replace({'m²': '', ',': ''}, regex=True), errors='coerce')\n",
        "    X['land_area'] = pd.to_numeric(X['land_area'].replace({'m²': '', ',': ''}, regex=True), errors='coerce')\n",
        "    X['has_rental_history'] = X['has_rental_history'].astype(int) if 'has_rental_history' in X.columns else 0\n",
        "    X['is_currently_rented'] = X['is_currently_rented'].astype(int) if 'is_currently_rented' in X.columns else 0\n",
        "\n",
        "    # 提取 property_history 特征\n",
        "    if 'property_history' in X.columns:\n",
        "        X['transaction_count'], X['days_since_last_transaction'], X['has_built_event'] = zip(\n",
        "            *X['property_history'].apply(extract_property_history_features)\n",
        "        )\n",
        "        X = X.drop(columns=['property_history'])\n",
        "    else:\n",
        "        X['transaction_count'] = 0\n",
        "        X['days_since_last_transaction'] = -1\n",
        "        X['has_built_event'] = 0\n",
        "\n",
        "    # 处理类别型特征（如 suburb）\n",
        "    if 'suburb' in X.columns:\n",
        "        X['suburb'] = X['suburb'].astype('category').cat.codes\n",
        "\n",
        "    # 将所有特征转为数值型，并填充缺失值\n",
        "    for col in X.columns:\n",
        "        X[col] = pd.to_numeric(X[col], errors='coerce')\n",
        "\n",
        "    # 处理无穷大值，将其替换为数据集中的最大合理值或默认值\n",
        "    X.replace([float('inf'), -float('inf')], -1, inplace=True)\n",
        "\n",
        "    X = X.fillna(X.mean())\n",
        "\n",
        "    if not for_prediction:\n",
        "        if 'status' in df.columns:\n",
        "            y = df['status'].astype(int)  # 0/1\n",
        "            # 改为警告而非抛错\n",
        "            uniques = y.unique()\n",
        "            print(\">> 标签唯一值：\", uniques)\n",
        "            if len(uniques) < 2:\n",
        "                print(\"警告：训练集只有单一标签，无法训练有区分度模型，请检查数据视图或查询。\")\n",
        "            return X, y, None\n",
        "        else:\n",
        "            print(\"错误：训练数据中缺少 status 字段\")\n",
        "            return None, None, None\n",
        "    else:\n",
        "        return X\n",
        "\n",
        "\n",
        "def train_model(X, y):\n",
        "    print(\"开始模型训练...\")\n",
        "    # 增加 stratify 以保持正负样本比例\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "    # 修复语法，增加 class_weight\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        class_weight='balanced',\n",
        "        random_state=42\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"模型准确率: {accuracy:.2f}\")\n",
        "\n",
        "    joblib.dump((model, X.columns.tolist()), 'property_status_model.joblib')\n",
        "    print(\"模型和特征名称已保存为 'property_status_model.joblib'\")\n",
        "\n",
        "    return model, X.columns.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjSKSvNstsCK"
      },
      "source": [
        "第五步：预测和存储结果"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OF6MfFFtsCK"
      },
      "outputs": [],
      "source": [
        "def predict_and_store(model, feature_names, prediction_df, clear_old_data=True):\n",
        "    \"\"\"\n",
        "    预测并将结果存储到数据库。\n",
        "    \n",
        "    参数:\n",
        "    model: 训练好的模型\n",
        "    feature_names: 特征名称列表\n",
        "    prediction_df: 需要预测的数据\n",
        "    clear_old_data: 是否在预测前清除旧数据\n",
        "    \"\"\"\n",
        "    print(\"开始预测并存储结果...\")\n",
        "\n",
        "    # 创建 Supabase 客户端\n",
        "    supabase_client = create_supabase_client()\n",
        "\n",
        "    # 如果需要，清空旧的预测数据\n",
        "    if clear_old_data:\n",
        "        clear_previous_predictions()\n",
        "\n",
        "    # 预处理数据\n",
        "    X_pred = preprocess_data(prediction_df, for_prediction=True)\n",
        "    X_pred = X_pred.reindex(columns=feature_names, fill_value=0)  # 确保所有列都匹配\n",
        "\n",
        "    # 预测结果和置信度\n",
        "    predictions = model.predict(X_pred)\n",
        "    confidence_scores = model.predict_proba(X_pred).max(axis=1)\n",
        "\n",
        "    # 映射预测结果\n",
        "    mapping = {1: 'for Sale', 0: 'not for Sale'}\n",
        "    predicted_statuses = [mapping.get(int(p), str(p)) for p in predictions]\n",
        "\n",
        "    # 当前时间精确到秒\n",
        "    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "    # 准备要插入的数据\n",
        "    records_to_insert = []\n",
        "    for idx, row in prediction_df.iterrows():\n",
        "        property_id = row['id']\n",
        "        predicted_status = predicted_statuses[idx]\n",
        "        confidence_score = float(confidence_scores[idx])\n",
        "\n",
        "        records_to_insert.append({\n",
        "            'property_id': property_id,\n",
        "            'predicted_status': predicted_status,\n",
        "            'confidence_score': confidence_score,\n",
        "            'predicted_at': current_time\n",
        "        })\n",
        "\n",
        "    # 转换所有 numpy 类型为原生类型\n",
        "    records_to_insert = to_json_serializable(records_to_insert)\n",
        "\n",
        "    # 分批插入数据（如果数据量很大）\n",
        "    batch_size = 1000\n",
        "    total_inserted = 0\n",
        "    \n",
        "    for i in range(0, len(records_to_insert), batch_size):\n",
        "        batch = records_to_insert[i:i+batch_size]\n",
        "        \n",
        "        # 批量插入数据\n",
        "        try:\n",
        "            result = supabase_client.table('property_status').insert(batch).execute()\n",
        "\n",
        "            # 检查插入结果并记录日志\n",
        "            if result.data:\n",
        "                batch_inserted = len(result.data)\n",
        "                total_inserted += batch_inserted\n",
        "                print(f\"成功插入批次 {i//batch_size + 1}，共 {batch_inserted} 条记录\")\n",
        "                \n",
        "                # 显示前几条记录作为示例\n",
        "                for j, inserted_record in enumerate(result.data[:3]):  # 只显示前3条\n",
        "                    inserted_id = inserted_record.get('property_id')\n",
        "                    predicted_at = inserted_record.get('predicted_at', current_time)\n",
        "                    print(f\"  成功存储预测结果 - ID: {inserted_id}, 预测状态: {inserted_record['predicted_status']}, 置信度: {inserted_record['confidence_score']:.4f}, 预测时间: {predicted_at}\")\n",
        "                    \n",
        "                if len(result.data) > 3:\n",
        "                    print(f\"  ... 还有 {len(result.data) - 3} 条记录\")\n",
        "            else:\n",
        "                print(f\"警告: 批次 {i//batch_size + 1} 插入成功，但未能检索到插入的记录。\")\n",
        "        except Exception as insert_error:\n",
        "            print(f\"错误: 批量存储预测结果时发生错误 - 错误详情: {insert_error}\")\n",
        "    \n",
        "    print(f\"总共插入 {total_inserted} 条预测记录\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b60Coj1CtsCL"
      },
      "source": [
        "第六步：主程序"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kL7I9VEQtsCL"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    print(\"程序开始运行...\")\n",
        "    try:\n",
        "        # 获取训练数据\n",
        "        training_df = fetch_training_data()\n",
        "        if training_df is None or training_df.empty:\n",
        "            print(\"错误: 没有获取到有效的训练数据，程序终止。\")\n",
        "            return\n",
        "\n",
        "        # 数据预处理\n",
        "        X, y, le = preprocess_data(training_df)\n",
        "        if X is None or y is None:\n",
        "            print(\"错误: 数据预处理失败，程序终止。\")\n",
        "            return\n",
        "\n",
        "        # 训练模型\n",
        "        model, feature_names = train_model(X, y)\n",
        "\n",
        "        # 获取预测数据 - 这里我们演示获取所有需要预测的数据\n",
        "        # 可以根据需要修改过滤条件，例如获取特定城市的所有数据\n",
        "        print(\"\\n=== 获取所有待预测数据 ===\")\n",
        "        prediction_df = fetch_prediction_data()\n",
        "        \n",
        "        if prediction_df is None or prediction_df.empty:\n",
        "            print(\"警告: 没有获取到需要预测的数据，程序终止。\")\n",
        "            return\n",
        "\n",
        "        # 预测并存储结果\n",
        "        # 注意：这里设置 clear_old_data=True，表示在第一次运行时会删除之前的预测数据\n",
        "        predict_and_store(model, feature_names, prediction_df, clear_old_data=True)\n",
        "        print(\"预测完成，结果已存储到数据库。\")\n",
        "\n",
        "        # 额外演示：获取特定区域（如Wellington）的所有数据进行预测\n",
        "        print(\"\\n=== 获取Wellington地区待预测数据 ===\")\n",
        "        wellington_df = fetch_prediction_data(city_filter=\"Wellington\")\n",
        "        \n",
        "        if wellington_df is not None and not wellington_df.empty:\n",
        "            print(f\"获取到 {len(wellington_df)} 条 Wellington 地区的待预测数据\")\n",
        "            # 注意：这里设置 clear_old_data=False，表示不清除之前的数据\n",
        "            # 如果需要清除，可以设置为True，或者单独调用 clear_previous_predictions()\n",
        "            predict_and_store(model, feature_names, wellington_df, clear_old_data=False)\n",
        "            print(\"Wellington地区预测完成，结果已存储到数据库。\")\n",
        "        else:\n",
        "            print(\"没有获取到 Wellington 地区的待预测数据\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"错误: 程序运行时发生错误：{e}\")\n",
        "        import traceback\n",
        "        print(\"错误详情:\")\n",
        "        print(traceback.format_exc())\n",
        "\n",
        "    print(\"程序运行结束。\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
