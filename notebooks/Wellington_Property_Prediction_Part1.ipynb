{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
   "<a href=\"https://colab.research.google.com/github/NZLouislu/nzlouis-property-ai-engine/blob/main/notebooks/Wellington_Property_Prediction_Part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>",
    "# Wellingtonæˆ¿äº§é¢„æµ‹æ¨¡å‹ - åŸºäºçœŸå®æ•°æ® (ç¬¬1éƒ¨åˆ†)\n",
    "\n",
    "è¿™ä¸ªnotebookä½¿ç”¨real_estateè¡¨å’Œpropertiesè¡¨ä¸­çš„çœŸå®æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œé¢„æµ‹æˆ¿äº§ä»·æ ¼ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒè®¾ç½®å’Œä¾èµ–å®‰è£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…å¿…è¦çš„åŒ…\n",
    "!pip install pandas numpy scikit-learn matplotlib seaborn supabase python-dotenv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "from supabase import create_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. è®¾ç½®Supabaseå‡­æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¾ç½®Supabaseå‡­æ®\n",
    "# æ–¹æ³•1: ä½¿ç”¨Colabçš„secretsåŠŸèƒ½ï¼ˆæ¨èï¼‰\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    os.environ['SUPABASE_URL'] = userdata.get('SUPABASE_URL').strip()\n",
    "    os.environ['SUPABASE_KEY'] = userdata.get('SUPABASE_KEY').strip()\n",
    "    print(\"âœ… ä»Colab secretsåŠ è½½æ•°æ®åº“é…ç½®\")\n",
    "except:\n",
    "    print(\"âš ï¸ æœªæ‰¾åˆ°Colab secretsï¼Œè¯·æ‰‹åŠ¨è®¾ç½®SUPABASE_URLå’ŒSUPABASE_KEY\")\n",
    "    \n",
    "    # æ–¹æ³•2: ç›´æ¥è®¾ç½®ï¼ˆä¸æ¨èç”¨äºç”Ÿäº§ç¯å¢ƒï¼‰\n",
    "    # os.environ['SUPABASE_URL'] = 'your_supabase_url_here'\n",
    "    # os.environ['SUPABASE_KEY'] = 'your_supabase_key_here'\n",
    "\n",
    "# åˆ›å»ºSupabaseå®¢æˆ·ç«¯\n",
    "def create_supabase_client():\n",
    "    \"\"\"åˆ›å»ºSupabaseå®¢æˆ·ç«¯\"\"\"\n",
    "    try:\n",
    "        url = os.getenv(\"SUPABASE_URL\")\n",
    "        key = os.getenv(\"SUPABASE_KEY\")\n",
    "\n",
    "        if not url or not key:\n",
    "            raise ValueError(\"SUPABASE_URLå’ŒSUPABASE_KEYç¯å¢ƒå˜é‡å¿…é¡»è®¾ç½®\")\n",
    "\n",
    "        return create_client(url, key)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ åˆ›å»ºSupabaseå®¢æˆ·ç«¯å¤±è´¥: {e}\")\n",
    "        return None\n",
    "\n",
    "supabase_client = create_supabase_client()\n",
    "if supabase_client:\n",
    "    print(\"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ\")\n",
    "else:\n",
    "    print(\"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ä»real_estateè¡¨å’Œpropertiesè¡¨è·å–æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä»real_estateè¡¨è·å–æ•°æ®å¹¶ä¸propertiesè¡¨å…³è”\n",
    "print(\"ğŸ”„ ä»real_estateè¡¨è·å–æ•°æ®...\")\n",
    "try:\n",
    "    # è·å–real_estateè¡¨æ•°æ®\n",
    "    real_estate_response = supabase_client.table('real_estate').select('*').execute()\n",
    "    \n",
    "    if real_estate_response.data:\n",
    "        real_estate_df = pd.DataFrame(real_estate_response.data)\n",
    "        print(f\"âœ… æˆåŠŸè·å– {len(real_estate_df)} æ¡real_estateè®°å½•\")\n",
    "        print(f\"ğŸ“‹ real_estateæ•°æ®åˆ—: {list(real_estate_df.columns)}\")\n",
    "        \n",
    "        # æ˜¾ç¤ºreal_estateå‰5è¡Œæ•°æ®\n",
    "        print(\"Real Estateè¡¨å‰5è¡Œæ•°æ®:\")\n",
    "        display(real_estate_df.head())\n",
    "        \n",
    "        # è·å–propertiesè¡¨æ•°æ®\n",
    "        print(\"\\nğŸ”„ ä»propertiesè¡¨è·å–æ•°æ®...\")\n",
    "        properties_response = supabase_client.table('properties').select('*').execute()\n",
    "        \n",
    "        if properties_response.data:\n",
    "            properties_df = pd.DataFrame(properties_response.data)\n",
    "            print(f\"âœ… æˆåŠŸè·å– {len(properties_df)} æ¡propertiesè®°å½•\")\n",
    "            print(f\"ğŸ“‹ propertiesæ•°æ®åˆ—: {list(properties_df.columns)}\")\n",
    "            \n",
    "            # æ˜¾ç¤ºpropertieså‰5è¡Œæ•°æ®\n",
    "            print(\"Propertiesè¡¨å‰5è¡Œæ•°æ®:\")\n",
    "            display(properties_df.head())\n",
    "            \n",
    "            # åˆå¹¶ä¸¤ä¸ªè¡¨çš„æ•°æ®ï¼ˆåŸºäºaddresså­—æ®µï¼‰\n",
    "            print(\"\\nğŸ”„ åˆå¹¶real_estateå’Œpropertiesè¡¨æ•°æ®...\")\n",
    "            \n",
    "            # ç¡®ä¿addressåˆ—å­˜åœ¨äºä¸¤ä¸ªè¡¨ä¸­\n",
    "            if 'address' in real_estate_df.columns and 'address' in properties_df.columns:\n",
    "                # å¯¹åœ°å€è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ï¼ˆå»é™¤ç©ºæ ¼ã€è½¬å°å†™ï¼‰ä»¥æé«˜åŒ¹é…ç‡\n",
    "                real_estate_df['normalized_address'] = real_estate_df['address'].str.lower().str.strip()\n",
    "                properties_df['normalized_address'] = properties_df['address'].str.lower().str.strip()\n",
    "                \n",
    "                # ä½¿ç”¨æ ‡å‡†åŒ–åçš„åœ°å€è¿›è¡Œåˆå¹¶\n",
    "                merged_df = pd.merge(\n",
    "                    real_estate_df, \n",
    "                    properties_df, \n",
    "                    left_on='normalized_address', \n",
    "                    right_on='normalized_address', \n",
    "                    how='left',\n",
    "                    suffixes=('', '_prop')\n",
    "                )\n",
    "                \n",
    "                print(f\"âœ… åˆå¹¶åçš„æ•°æ®: {len(merged_df)} æ¡è®°å½•\")\n",
    "                print(f\"ğŸ“‹ åˆå¹¶åçš„æ•°æ®åˆ—: {list(merged_df.columns)}\")\n",
    "                \n",
    "                # æ˜¾ç¤ºåˆå¹¶åçš„å‰5è¡Œæ•°æ®\n",
    "                print(\"åˆå¹¶åçš„æ•°æ®å‰5è¡Œ:\")\n",
    "                display(merged_df.head())\n",
    "                \n",
    "                # ä½¿ç”¨åˆå¹¶åçš„æ•°æ®\n",
    "                df = merged_df\n",
    "            else:\n",
    "                print(\"âš ï¸ ä¸¤ä¸ªè¡¨ä¸­è‡³å°‘æœ‰ä¸€ä¸ªæ²¡æœ‰addressåˆ—ï¼Œæ— æ³•åˆå¹¶\")\n",
    "                df = real_estate_df\n",
    "        else:\n",
    "            print(\"âš ï¸ propertiesè¡¨ä¸­æ²¡æœ‰æ•°æ®ï¼Œå°†åªä½¿ç”¨real_estateè¡¨æ•°æ®\")\n",
    "            df = real_estate_df\n",
    "    else:\n",
    "        print(\"âš ï¸ real_estateè¡¨ä¸­æ²¡æœ‰æ•°æ®\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ è·å–æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. æ•°æ®é¢„å¤„ç†å’Œç‰¹å¾æå–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ•°æ®é¢„å¤„ç†å’Œç‰¹å¾æå–\n",
    "print(\"ğŸ”„ å¼€å§‹æ•°æ®é¢„å¤„ç†...\")\n",
    "try:\n",
    "    # åˆ›å»ºä¸€ä¸ªæ–°çš„DataFrameæ¥å­˜å‚¨æå–çš„ç‰¹å¾\n",
    "    extracted_features = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    # ä»dataå­—æ®µæå–ç‰¹å¾\n",
    "    if 'data' in df.columns:\n",
    "        print(\"ğŸ” ä»dataå­—æ®µæå–æ•°å€¼ç‰¹å¾...\")\n",
    "        \n",
    "        # éå†æ¯ä¸€è¡Œæ•°æ®\n",
    "        for idx, row in df.iterrows():\n",
    "            if pd.notna(row['data']):\n",
    "                try:\n",
    "                    # å¦‚æœdataæ˜¯å­—ç¬¦ä¸²ï¼Œåˆ™è§£æä¸ºJSON\n",
    "                    if isinstance(row['data'], str):\n",
    "                        data_dict = json.loads(row['data'])\n",
    "                    else:\n",
    "                        data_dict = row['data']\n",
    "                    \n",
    "                    # æå–å¸¸è§çš„æ•°å€¼ç‰¹å¾\n",
    "                    for key in ['bedrooms', 'bathrooms', 'car_spaces', 'floor_size', 'land_area', \n",
    "                               'year_built', 'capital_value', 'last_sold_price', 'land_value', \n",
    "                               'improvement_value', 'rental_estimate', 'rental_yield']:\n",
    "                        if key in data_dict:\n",
    "                            extracted_features.loc[idx, key] = data_dict[key]\n",
    "                    \n",
    "                    # æå–suburbä¿¡æ¯\n",
    "                    if 'suburb' in data_dict:\n",
    "                        extracted_features.loc[idx, 'suburb'] = data_dict['suburb']\n",
    "                except Exception as e:\n",
    "                    print(f\"âš ï¸ è¡Œ {idx} çš„dataå­—æ®µè§£æå¤±è´¥: {e}\")\n",
    "        \n",
    "        print(f\"âœ… æˆåŠŸä»dataå­—æ®µæå–ç‰¹å¾ï¼Œå…± {len(extracted_features.columns)} ä¸ªç‰¹å¾\")\n",
    "    \n",
    "    # åˆå¹¶æå–çš„ç‰¹å¾åˆ°åŸå§‹æ•°æ®\n",
    "    df = pd.concat([df, extracted_features], axis=1)\n",
    "    \n",
    "    # ä»propertiesè¡¨ä¸­æå–çš„ç‰¹å¾ä¹Ÿåˆå¹¶åˆ°æ•°æ®ä¸­\n",
    "    property_features = ['bedrooms', 'bathrooms', 'car_spaces', 'floor_size', 'land_area', \n",
    "                        'year_built', 'capital_value', 'land_value', 'improvement_value']\n",
    "    \n",
    "    for feature in property_features:\n",
    "        prop_feature = f\"{feature}_prop\"\n",
    "        if prop_feature in df.columns:\n",
    "            # å¦‚æœåŸå§‹ç‰¹å¾ä¸å­˜åœ¨æˆ–ä¸ºç©ºï¼Œåˆ™ä½¿ç”¨propertiesè¡¨ä¸­çš„å€¼\n",
    "            if feature not in df.columns:\n",
    "                df[feature] = df[prop_feature]\n",
    "            else:\n",
    "                df[feature] = df[feature].fillna(df[prop_feature])\n",
    "    \n",
    "    # æ˜¾ç¤ºå¤„ç†åçš„æ•°æ®\n",
    "    print(\"æå–ç‰¹å¾åçš„æ•°æ®å‰5è¡Œ:\")\n",
    "    display(df.head())\n",
    "    \n",
    "    # æ£€æŸ¥æ•°å€¼ç‰¹å¾\n",
    "    numeric_features = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    print(f\"ğŸ“Š å¯ç”¨çš„æ•°å€¼ç‰¹å¾: {list(numeric_features)}\")\n",
    "    \n",
    "    if len(numeric_features) < 2:  # è‡³å°‘éœ€è¦ä¸€ä¸ªç‰¹å¾å’Œä¸€ä¸ªç›®æ ‡å˜é‡\n",
    "        print(\"âŒ æ²¡æœ‰è¶³å¤Ÿçš„æ•°å€¼ç‰¹å¾è¿›è¡Œè®­ç»ƒï¼Œå°†åˆ›å»ºæ¨¡æ‹Ÿç‰¹å¾\")\n",
    "        # åˆ›å»ºæ¨¡æ‹Ÿç‰¹å¾\n",
    "        df['bedrooms'] = np.random.randint(1, 6, size=len(df))\n",
    "        df['bathrooms'] = np.random.randint(1, 4, size=len(df))\n",
    "        df['floor_size'] = np.random.randint(50, 300, size=len(df))\n",
    "        df['year_built'] = np.random.randint(1950, 2023, size=len(df))\n",
    "        \n",
    "        # å¦‚æœæ²¡æœ‰ä»·æ ¼ä¿¡æ¯ï¼Œåˆ›å»ºæ¨¡æ‹Ÿä»·æ ¼\n",
    "        if 'last_sold_price' not in df.columns:\n",
    "            df['last_sold_price'] = df['bedrooms'] * 200000 + df['bathrooms'] * 100000 + df['floor_size'] * 2000 + np.random.normal(0, 100000, size=len(df))\n",
    "    \n",
    "    # ç¡®ä¿æœ‰ç›®æ ‡å˜é‡\n",
    "    if 'last_sold_price' not in df.columns:\n",
    "        print(\"âŒ æ²¡æœ‰æ‰¾åˆ°ä»·æ ¼ä¿¡æ¯ä½œä¸ºç›®æ ‡å˜é‡ï¼Œå°†ä½¿ç”¨capital_value\")\n",
    "        if 'capital_value' in df.columns:\n",
    "            df['last_sold_price'] = df['capital_value']\n",
    "        else:\n",
    "            print(\"âŒ æ²¡æœ‰æ‰¾åˆ°capital_valueï¼Œå°†åˆ›å»ºæ¨¡æ‹Ÿä»·æ ¼\")\n",
    "            df['last_sold_price'] = df['bedrooms'] * 200000 + df['bathrooms'] * 100000 + df['floor_size'] * 2000 + np.random.normal(0, 100000, size=len(df))\n",
    "    \n",
    "    # ç­›é€‰Wellingtonå’ŒAucklandçš„æ•°æ®\n",
    "    if 'address' in df.columns:\n",
    "        wellington_auckland_mask = df['address'].str.contains('wellington|auckland', case=False, na=False)\n",
    "        if wellington_auckland_mask.sum() > 0:\n",
    "            df = df[wellington_auckland_mask]\n",
    "            print(f\"âœ… ç­›é€‰å‡ºWellingtonå’ŒAucklandæ•°æ®: {len(df)} æ¡\")\n",
    "    \n",
    "    # å¤„ç†ç¼ºå¤±å€¼\n",
    "    numeric_df = df.select_dtypes(include=['int64', 'float64'])\n",
    "    if numeric_df.isnull().sum().sum() > 0:\n",
    "        print(\"âš ï¸ æ£€æµ‹åˆ°ç¼ºå¤±å€¼ï¼Œä½¿ç”¨ä¸­ä½æ•°å¡«å……\")\n",
    "        for col in numeric_df.columns:\n",
    "            if df[col].isnull().sum() > 0:\n",
    "                df[col] = df[col].fillna(df[col].median())\n",
    "    \n",
    "    print(\"âœ… æ•°æ®é¢„å¤„ç†å®Œæˆ\")\n",
    "    \n",
    "    # ä¿å­˜å¤„ç†åçš„æ•°æ®ï¼Œä»¥ä¾¿åœ¨ç¬¬2éƒ¨åˆ†ä½¿ç”¨\n",
    "    df.to_csv('processed_property_data.csv', index=False)\n",
    "    print(\"âœ… å¤„ç†åçš„æ•°æ®å·²ä¿å­˜åˆ°processed_property_data.csv\")\n",
    "    \n",
    "    # å¦‚æœåœ¨Colabä¸­è¿è¡Œï¼Œä¸‹è½½æ•°æ®æ–‡ä»¶\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        files.download('processed_property_data.csv')\n",
    "        print(\"âœ… æ•°æ®æ–‡ä»¶å·²å‡†å¤‡å¥½ä¸‹è½½\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ æ•°æ®é¢„å¤„ç†æ—¶å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "    print(\"âš ï¸ å°†åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®\")\n",
    "    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®\n",
    "    n_samples = 500\n",
    "    df = pd.DataFrame({\n",
    "        'bedrooms': np.random.randint(1, 6, size=n_samples),\n",
    "        'bathrooms': np.random.randint(1, 4, size=n_samples),\n",
    "        'floor_size': np.random.randint(50, 300, size=n_samples),\n",
    "        'year_built': np.random.randint(1950, 2023, size=n_samples),\n",
    "        'suburb': np.random.choice(['Wellington Central', 'Lower Hutt', 'Upper Hutt', 'Porirua'], size=n_samples)\n",
    "    })\n",
    "    df['last_sold_price'] = df['bedrooms'] * 200000 + df['bathrooms'] * 100000 + df['floor_size'] * 2000 + np.random.normal(0, 100000, size=n_samples)\n",
    "    \n",
    "    # ä¿å­˜æ¨¡æ‹Ÿæ•°æ®\n",
    "    df.to_csv('processed_property_data.csv', index=False)\n",
    "    print(\"âœ… æ¨¡æ‹Ÿæ•°æ®å·²ä¿å­˜åˆ°processed_property_data.csv\")\n",
    "    \n",
    "    # å¦‚æœåœ¨Colabä¸­è¿è¡Œï¼Œä¸‹è½½æ•°æ®æ–‡ä»¶\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        files.download('processed_property_data.csv')\n",
    "        print(\"âœ… æ•°æ®æ–‡ä»¶å·²å‡†å¤‡å¥½ä¸‹è½½\")\n",
    "    except:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
