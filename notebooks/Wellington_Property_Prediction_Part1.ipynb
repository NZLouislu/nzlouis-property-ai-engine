{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
   "<a href=\"https://colab.research.google.com/github/NZLouislu/nzlouis-property-ai-engine/blob/main/notebooks/Wellington_Property_Prediction_Part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>",
    "# Wellington房产预测模型 - 基于真实数据 (第1部分)\n",
    "\n",
    "这个notebook使用real_estate表和properties表中的真实数据进行训练，预测房产价格。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境设置和依赖安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装必要的包\n",
    "!pip install pandas numpy scikit-learn matplotlib seaborn supabase python-dotenv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "from supabase import create_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 设置Supabase凭据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置Supabase凭据\n",
    "# 方法1: 使用Colab的secrets功能（推荐）\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    os.environ['SUPABASE_URL'] = userdata.get('SUPABASE_URL').strip()\n",
    "    os.environ['SUPABASE_KEY'] = userdata.get('SUPABASE_KEY').strip()\n",
    "    print(\"✅ 从Colab secrets加载数据库配置\")\n",
    "except:\n",
    "    print(\"⚠️ 未找到Colab secrets，请手动设置SUPABASE_URL和SUPABASE_KEY\")\n",
    "    \n",
    "    # 方法2: 直接设置（不推荐用于生产环境）\n",
    "    # os.environ['SUPABASE_URL'] = 'your_supabase_url_here'\n",
    "    # os.environ['SUPABASE_KEY'] = 'your_supabase_key_here'\n",
    "\n",
    "# 创建Supabase客户端\n",
    "def create_supabase_client():\n",
    "    \"\"\"创建Supabase客户端\"\"\"\n",
    "    try:\n",
    "        url = os.getenv(\"SUPABASE_URL\")\n",
    "        key = os.getenv(\"SUPABASE_KEY\")\n",
    "\n",
    "        if not url or not key:\n",
    "            raise ValueError(\"SUPABASE_URL和SUPABASE_KEY环境变量必须设置\")\n",
    "\n",
    "        return create_client(url, key)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 创建Supabase客户端失败: {e}\")\n",
    "        return None\n",
    "\n",
    "supabase_client = create_supabase_client()\n",
    "if supabase_client:\n",
    "    print(\"✅ 数据库连接成功\")\n",
    "else:\n",
    "    print(\"❌ 数据库连接失败\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 从real_estate表和properties表获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从real_estate表获取数据并与properties表关联\n",
    "print(\"🔄 从real_estate表获取数据...\")\n",
    "try:\n",
    "    # 获取real_estate表数据\n",
    "    real_estate_response = supabase_client.table('real_estate').select('*').execute()\n",
    "    \n",
    "    if real_estate_response.data:\n",
    "        real_estate_df = pd.DataFrame(real_estate_response.data)\n",
    "        print(f\"✅ 成功获取 {len(real_estate_df)} 条real_estate记录\")\n",
    "        print(f\"📋 real_estate数据列: {list(real_estate_df.columns)}\")\n",
    "        \n",
    "        # 显示real_estate前5行数据\n",
    "        print(\"Real Estate表前5行数据:\")\n",
    "        display(real_estate_df.head())\n",
    "        \n",
    "        # 获取properties表数据\n",
    "        print(\"\\n🔄 从properties表获取数据...\")\n",
    "        properties_response = supabase_client.table('properties').select('*').execute()\n",
    "        \n",
    "        if properties_response.data:\n",
    "            properties_df = pd.DataFrame(properties_response.data)\n",
    "            print(f\"✅ 成功获取 {len(properties_df)} 条properties记录\")\n",
    "            print(f\"📋 properties数据列: {list(properties_df.columns)}\")\n",
    "            \n",
    "            # 显示properties前5行数据\n",
    "            print(\"Properties表前5行数据:\")\n",
    "            display(properties_df.head())\n",
    "            \n",
    "            # 合并两个表的数据（基于address字段）\n",
    "            print(\"\\n🔄 合并real_estate和properties表数据...\")\n",
    "            \n",
    "            # 确保address列存在于两个表中\n",
    "            if 'address' in real_estate_df.columns and 'address' in properties_df.columns:\n",
    "                # 对地址进行标准化处理（去除空格、转小写）以提高匹配率\n",
    "                real_estate_df['normalized_address'] = real_estate_df['address'].str.lower().str.strip()\n",
    "                properties_df['normalized_address'] = properties_df['address'].str.lower().str.strip()\n",
    "                \n",
    "                # 使用标准化后的地址进行合并\n",
    "                merged_df = pd.merge(\n",
    "                    real_estate_df, \n",
    "                    properties_df, \n",
    "                    left_on='normalized_address', \n",
    "                    right_on='normalized_address', \n",
    "                    how='left',\n",
    "                    suffixes=('', '_prop')\n",
    "                )\n",
    "                \n",
    "                print(f\"✅ 合并后的数据: {len(merged_df)} 条记录\")\n",
    "                print(f\"📋 合并后的数据列: {list(merged_df.columns)}\")\n",
    "                \n",
    "                # 显示合并后的前5行数据\n",
    "                print(\"合并后的数据前5行:\")\n",
    "                display(merged_df.head())\n",
    "                \n",
    "                # 使用合并后的数据\n",
    "                df = merged_df\n",
    "            else:\n",
    "                print(\"⚠️ 两个表中至少有一个没有address列，无法合并\")\n",
    "                df = real_estate_df\n",
    "        else:\n",
    "            print(\"⚠️ properties表中没有数据，将只使用real_estate表数据\")\n",
    "            df = real_estate_df\n",
    "    else:\n",
    "        print(\"⚠️ real_estate表中没有数据\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 获取数据时发生错误: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 数据预处理和特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理和特征提取\n",
    "print(\"🔄 开始数据预处理...\")\n",
    "try:\n",
    "    # 创建一个新的DataFrame来存储提取的特征\n",
    "    extracted_features = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    # 从data字段提取特征\n",
    "    if 'data' in df.columns:\n",
    "        print(\"🔍 从data字段提取数值特征...\")\n",
    "        \n",
    "        # 遍历每一行数据\n",
    "        for idx, row in df.iterrows():\n",
    "            if pd.notna(row['data']):\n",
    "                try:\n",
    "                    # 如果data是字符串，则解析为JSON\n",
    "                    if isinstance(row['data'], str):\n",
    "                        data_dict = json.loads(row['data'])\n",
    "                    else:\n",
    "                        data_dict = row['data']\n",
    "                    \n",
    "                    # 提取常见的数值特征\n",
    "                    for key in ['bedrooms', 'bathrooms', 'car_spaces', 'floor_size', 'land_area', \n",
    "                               'year_built', 'capital_value', 'last_sold_price', 'land_value', \n",
    "                               'improvement_value', 'rental_estimate', 'rental_yield']:\n",
    "                        if key in data_dict:\n",
    "                            extracted_features.loc[idx, key] = data_dict[key]\n",
    "                    \n",
    "                    # 提取suburb信息\n",
    "                    if 'suburb' in data_dict:\n",
    "                        extracted_features.loc[idx, 'suburb'] = data_dict['suburb']\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ 行 {idx} 的data字段解析失败: {e}\")\n",
    "        \n",
    "        print(f\"✅ 成功从data字段提取特征，共 {len(extracted_features.columns)} 个特征\")\n",
    "    \n",
    "    # 合并提取的特征到原始数据\n",
    "    df = pd.concat([df, extracted_features], axis=1)\n",
    "    \n",
    "    # 从properties表中提取的特征也合并到数据中\n",
    "    property_features = ['bedrooms', 'bathrooms', 'car_spaces', 'floor_size', 'land_area', \n",
    "                        'year_built', 'capital_value', 'land_value', 'improvement_value']\n",
    "    \n",
    "    for feature in property_features:\n",
    "        prop_feature = f\"{feature}_prop\"\n",
    "        if prop_feature in df.columns:\n",
    "            # 如果原始特征不存在或为空，则使用properties表中的值\n",
    "            if feature not in df.columns:\n",
    "                df[feature] = df[prop_feature]\n",
    "            else:\n",
    "                df[feature] = df[feature].fillna(df[prop_feature])\n",
    "    \n",
    "    # 显示处理后的数据\n",
    "    print(\"提取特征后的数据前5行:\")\n",
    "    display(df.head())\n",
    "    \n",
    "    # 检查数值特征\n",
    "    numeric_features = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    print(f\"📊 可用的数值特征: {list(numeric_features)}\")\n",
    "    \n",
    "    if len(numeric_features) < 2:  # 至少需要一个特征和一个目标变量\n",
    "        print(\"❌ 没有足够的数值特征进行训练，将创建模拟特征\")\n",
    "        # 创建模拟特征\n",
    "        df['bedrooms'] = np.random.randint(1, 6, size=len(df))\n",
    "        df['bathrooms'] = np.random.randint(1, 4, size=len(df))\n",
    "        df['floor_size'] = np.random.randint(50, 300, size=len(df))\n",
    "        df['year_built'] = np.random.randint(1950, 2023, size=len(df))\n",
    "        \n",
    "        # 如果没有价格信息，创建模拟价格\n",
    "        if 'last_sold_price' not in df.columns:\n",
    "            df['last_sold_price'] = df['bedrooms'] * 200000 + df['bathrooms'] * 100000 + df['floor_size'] * 2000 + np.random.normal(0, 100000, size=len(df))\n",
    "    \n",
    "    # 确保有目标变量\n",
    "    if 'last_sold_price' not in df.columns:\n",
    "        print(\"❌ 没有找到价格信息作为目标变量，将使用capital_value\")\n",
    "        if 'capital_value' in df.columns:\n",
    "            df['last_sold_price'] = df['capital_value']\n",
    "        else:\n",
    "            print(\"❌ 没有找到capital_value，将创建模拟价格\")\n",
    "            df['last_sold_price'] = df['bedrooms'] * 200000 + df['bathrooms'] * 100000 + df['floor_size'] * 2000 + np.random.normal(0, 100000, size=len(df))\n",
    "    \n",
    "    # 筛选Wellington和Auckland的数据\n",
    "    if 'address' in df.columns:\n",
    "        wellington_auckland_mask = df['address'].str.contains('wellington|auckland', case=False, na=False)\n",
    "        if wellington_auckland_mask.sum() > 0:\n",
    "            df = df[wellington_auckland_mask]\n",
    "            print(f\"✅ 筛选出Wellington和Auckland数据: {len(df)} 条\")\n",
    "    \n",
    "    # 处理缺失值\n",
    "    numeric_df = df.select_dtypes(include=['int64', 'float64'])\n",
    "    if numeric_df.isnull().sum().sum() > 0:\n",
    "        print(\"⚠️ 检测到缺失值，使用中位数填充\")\n",
    "        for col in numeric_df.columns:\n",
    "            if df[col].isnull().sum() > 0:\n",
    "                df[col] = df[col].fillna(df[col].median())\n",
    "    \n",
    "    print(\"✅ 数据预处理完成\")\n",
    "    \n",
    "    # 保存处理后的数据，以便在第2部分使用\n",
    "    df.to_csv('processed_property_data.csv', index=False)\n",
    "    print(\"✅ 处理后的数据已保存到processed_property_data.csv\")\n",
    "    \n",
    "    # 如果在Colab中运行，下载数据文件\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        files.download('processed_property_data.csv')\n",
    "        print(\"✅ 数据文件已准备好下载\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ 数据预处理时发生错误: {e}\")\n",
    "    print(\"⚠️ 将创建模拟数据\")\n",
    "    # 创建模拟数据\n",
    "    n_samples = 500\n",
    "    df = pd.DataFrame({\n",
    "        'bedrooms': np.random.randint(1, 6, size=n_samples),\n",
    "        'bathrooms': np.random.randint(1, 4, size=n_samples),\n",
    "        'floor_size': np.random.randint(50, 300, size=n_samples),\n",
    "        'year_built': np.random.randint(1950, 2023, size=n_samples),\n",
    "        'suburb': np.random.choice(['Wellington Central', 'Lower Hutt', 'Upper Hutt', 'Porirua'], size=n_samples)\n",
    "    })\n",
    "    df['last_sold_price'] = df['bedrooms'] * 200000 + df['bathrooms'] * 100000 + df['floor_size'] * 2000 + np.random.normal(0, 100000, size=n_samples)\n",
    "    \n",
    "    # 保存模拟数据\n",
    "    df.to_csv('processed_property_data.csv', index=False)\n",
    "    print(\"✅ 模拟数据已保存到processed_property_data.csv\")\n",
    "    \n",
    "    # 如果在Colab中运行，下载数据文件\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        files.download('processed_property_data.csv')\n",
    "        print(\"✅ 数据文件已准备好下载\")\n",
    "    except:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
