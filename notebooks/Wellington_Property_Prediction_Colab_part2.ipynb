{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualization_section"
   },
   "source": [
    "## 6. 数据可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize_data"
   },
   "outputs": [],
   "source": [
    "# 数据可视化\n",
    "if 'processed_data' in locals() and len(processed_data) > 0:\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # 1. 目标变量分布\n",
    "    plt.subplot(2, 2, 1)\n",
    "    target_counts = pd.Series(y).value_counts()\n",
    "    plt.pie(target_counts.values, labels=['不太可能出售', '可能出售'] if len(target_counts) == 2 else target_counts.index, \n",
    "            autopct='%1.1f%%', colors=['lightcoral', 'lightgreen'])\n",
    "    plt.title('目标变量分布', fontsize=14)\n",
    "    \n",
    "    # 2. 数值特征相关性\n",
    "    plt.subplot(2, 2, 2)\n",
    "    numeric_cols = processed_data.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 1:\n",
    "        corr = processed_data[numeric_cols].corr()\n",
    "        sns.heatmap(corr, annot=False, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "        plt.title('特征相关性矩阵', fontsize=14)\n",
    "    \n",
    "    # 3. 特征重要性（如果有足够的特征）\n",
    "    plt.subplot(2, 2, 3)\n",
    "    if len(feature_names) > 0:\n",
    "        # 使用随机森林计算特征重要性\n",
    "        rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        rf.fit(X, y)\n",
    "        importances = pd.Series(rf.feature_importances_, index=feature_names)\n",
    "        importances = importances.sort_values(ascending=False)\n",
    "        top_features = importances.head(10)\n",
    "        top_features.plot(kind='barh')\n",
    "        plt.title('特征重要性 (Top 10)', fontsize=14)\n",
    "        plt.xlabel('重要性')\n",
    "    \n",
    "    # 4. 类别分布（如果有类别特征）\n",
    "    plt.subplot(2, 2, 4)\n",
    "    if 'is_wellington' in processed_data.columns and 'is_auckland' in processed_data.columns:\n",
    "        location_data = pd.DataFrame({\n",
    "            'Wellington': [processed_data[processed_data['is_wellington'] == 1]['target'].mean()],\n",
    "            'Auckland': [processed_data[processed_data['is_auckland'] == 1]['target'].mean()],\n",
    "            'Other': [processed_data[(processed_data['is_wellington'] == 0) & \n",
    "                                    (processed_data['is_auckland'] == 0)]['target'].mean()]\n",
    "        })\n",
    "        location_data.plot(kind='bar')\n",
    "        plt.title('各地区出售可能性', fontsize=14)\n",
    "        plt.ylabel('出售可能性')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"⚠️ 没有可视化的数据\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_section"
   },
   "source": [
    "## 7. 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_model"
   },
   "outputs": [],
   "source": [
    "print(\"🔄 训练模型...\")\n",
    "# 分割数据\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 标准化特征\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 创建集成模型\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=42, n_jobs=-1)\n",
    "gb = GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=8, random_state=42)\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[('rf', rf), ('gb', gb), ('lr', lr)], \n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "ensemble.fit(X_train_scaled, y_train)\n",
    "model = ensemble\n",
    "\n",
    "print(\"✅ 模型训练完成!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluation_section"
   },
   "source": [
    "## 8. 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate_model"
   },
   "outputs": [],
   "source": [
    "print(\"🔄 评估模型...\")\n",
    "# 评估模型\n",
    "train_accuracy = model.score(X_train_scaled, y_train)\n",
    "test_accuracy = model.score(X_test_scaled, y_test)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "evaluation_results = {\n",
    "    \"训练准确率\": train_accuracy,\n",
    "    \"测试准确率\": test_accuracy,\n",
    "    \"精确率\": classification_rep['weighted avg']['precision'],\n",
    "    \"召回率\": classification_rep['weighted avg']['recall'],\n",
    "    \"F1分数\": classification_rep['weighted avg']['f1-score']\n",
    "}\n",
    "\n",
    "print(\"\\n📋 模型评估结果:\")\n",
    "for metric, value in evaluation_results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\n📊 详细分类报告:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 混淆矩阵可视化\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('混淆矩阵')\n",
    "plt.ylabel('真实标签')\n",
    "plt.xlabel('预测标签')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}