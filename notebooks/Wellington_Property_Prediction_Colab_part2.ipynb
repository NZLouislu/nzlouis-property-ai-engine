{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualization_section"
   },
   "source": [
    "## 6. æ•°æ®å¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize_data"
   },
   "outputs": [],
   "source": [
    "# æ•°æ®å¯è§†åŒ–\n",
    "if 'processed_data' in locals() and len(processed_data) > 0:\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # 1. ç›®æ ‡å˜é‡åˆ†å¸ƒ\n",
    "    plt.subplot(2, 2, 1)\n",
    "    target_counts = pd.Series(y).value_counts()\n",
    "    plt.pie(target_counts.values, labels=['ä¸å¤ªå¯èƒ½å‡ºå”®', 'å¯èƒ½å‡ºå”®'] if len(target_counts) == 2 else target_counts.index, \n",
    "            autopct='%1.1f%%', colors=['lightcoral', 'lightgreen'])\n",
    "    plt.title('ç›®æ ‡å˜é‡åˆ†å¸ƒ', fontsize=14)\n",
    "    \n",
    "    # 2. æ•°å€¼ç‰¹å¾ç›¸å…³æ€§\n",
    "    plt.subplot(2, 2, 2)\n",
    "    numeric_cols = processed_data.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 1:\n",
    "        corr = processed_data[numeric_cols].corr()\n",
    "        sns.heatmap(corr, annot=False, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "        plt.title('ç‰¹å¾ç›¸å…³æ€§çŸ©é˜µ', fontsize=14)\n",
    "    \n",
    "    # 3. ç‰¹å¾é‡è¦æ€§ï¼ˆå¦‚æœæœ‰è¶³å¤Ÿçš„ç‰¹å¾ï¼‰\n",
    "    plt.subplot(2, 2, 3)\n",
    "    if len(feature_names) > 0:\n",
    "        # ä½¿ç”¨éšæœºæ£®æ—è®¡ç®—ç‰¹å¾é‡è¦æ€§\n",
    "        rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        rf.fit(X, y)\n",
    "        importances = pd.Series(rf.feature_importances_, index=feature_names)\n",
    "        importances = importances.sort_values(ascending=False)\n",
    "        top_features = importances.head(10)\n",
    "        top_features.plot(kind='barh')\n",
    "        plt.title('ç‰¹å¾é‡è¦æ€§ (Top 10)', fontsize=14)\n",
    "        plt.xlabel('é‡è¦æ€§')\n",
    "    \n",
    "    # 4. ç±»åˆ«åˆ†å¸ƒï¼ˆå¦‚æœæœ‰ç±»åˆ«ç‰¹å¾ï¼‰\n",
    "    plt.subplot(2, 2, 4)\n",
    "    if 'is_wellington' in processed_data.columns and 'is_auckland' in processed_data.columns:\n",
    "        location_data = pd.DataFrame({\n",
    "            'Wellington': [processed_data[processed_data['is_wellington'] == 1]['target'].mean()],\n",
    "            'Auckland': [processed_data[processed_data['is_auckland'] == 1]['target'].mean()],\n",
    "            'Other': [processed_data[(processed_data['is_wellington'] == 0) & \n",
    "                                    (processed_data['is_auckland'] == 0)]['target'].mean()]\n",
    "        })\n",
    "        location_data.plot(kind='bar')\n",
    "        plt.title('å„åœ°åŒºå‡ºå”®å¯èƒ½æ€§', fontsize=14)\n",
    "        plt.ylabel('å‡ºå”®å¯èƒ½æ€§')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"âš ï¸ æ²¡æœ‰å¯è§†åŒ–çš„æ•°æ®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_section"
   },
   "source": [
    "## 7. æ¨¡å‹è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_model"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ”„ è®­ç»ƒæ¨¡å‹...\")\n",
    "# åˆ†å‰²æ•°æ®\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# æ ‡å‡†åŒ–ç‰¹å¾\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# åˆ›å»ºé›†æˆæ¨¡å‹\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=42, n_jobs=-1)\n",
    "gb = GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=8, random_state=42)\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[('rf', rf), ('gb', gb), ('lr', lr)], \n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# è®­ç»ƒæ¨¡å‹\n",
    "ensemble.fit(X_train_scaled, y_train)\n",
    "model = ensemble\n",
    "\n",
    "print(\"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluation_section"
   },
   "source": [
    "## 8. æ¨¡å‹è¯„ä¼°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate_model"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ”„ è¯„ä¼°æ¨¡å‹...\")\n",
    "# è¯„ä¼°æ¨¡å‹\n",
    "train_accuracy = model.score(X_train_scaled, y_train)\n",
    "test_accuracy = model.score(X_test_scaled, y_test)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "evaluation_results = {\n",
    "    \"è®­ç»ƒå‡†ç¡®ç‡\": train_accuracy,\n",
    "    \"æµ‹è¯•å‡†ç¡®ç‡\": test_accuracy,\n",
    "    \"ç²¾ç¡®ç‡\": classification_rep['weighted avg']['precision'],\n",
    "    \"å¬å›ç‡\": classification_rep['weighted avg']['recall'],\n",
    "    \"F1åˆ†æ•°\": classification_rep['weighted avg']['f1-score']\n",
    "}\n",
    "\n",
    "print(\"\\nğŸ“‹ æ¨¡å‹è¯„ä¼°ç»“æœ:\")\n",
    "for metric, value in evaluation_results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nğŸ“Š è¯¦ç»†åˆ†ç±»æŠ¥å‘Š:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# æ··æ·†çŸ©é˜µå¯è§†åŒ–\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('æ··æ·†çŸ©é˜µ')\n",
    "plt.ylabel('çœŸå®æ ‡ç­¾')\n",
    "plt.xlabel('é¢„æµ‹æ ‡ç­¾')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}