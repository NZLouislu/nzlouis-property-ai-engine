{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
   "<a href=\"https://colab.research.google.com/github/NZLouislu/nzlouis-property-ai-engine/blob/main/notebooks/Wellington_Property_Prediction_Part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>",
    "# Wellingtonæˆ¿äº§é¢„æµ‹æ¨¡å‹ - åŸºäºçœŸå®æ•°æ® (ç¬¬2éƒ¨åˆ†)\n",
    "\n",
    "è¿™ä¸ªnotebookæ˜¯Wellingtonæˆ¿äº§é¢„æµ‹æ¨¡å‹çš„ç¬¬2éƒ¨åˆ†ï¼ŒåŒ…å«ç‰¹å¾å·¥ç¨‹ã€æ¨¡å‹è®­ç»ƒå’Œé¢„æµ‹åŠŸèƒ½ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. åŠ è½½æ•°æ®å’Œç¯å¢ƒè®¾ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…å¿…è¦çš„åŒ…\n",
    "!pip install pandas numpy scikit-learn matplotlib seaborn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# ä¸Šä¼ ç¬¬1éƒ¨åˆ†ç”Ÿæˆçš„æ•°æ®æ–‡ä»¶\n",
    "try:\n",
    "    from google.colab import files\n",
    "    print(\"è¯·ä¸Šä¼ ç¬¬1éƒ¨åˆ†ç”Ÿæˆçš„processed_property_data.csvæ–‡ä»¶\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    # åŠ è½½ä¸Šä¼ çš„æ•°æ®æ–‡ä»¶\n",
    "    df = pd.read_csv('processed_property_data.csv')\n",
    "    print(f\"âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼Œå…± {len(df)} æ¡è®°å½•\")\n",
    "except:\n",
    "    print(\"âš ï¸ æ— æ³•ä¸Šä¼ æ–‡ä»¶æˆ–ä¸åœ¨Colabç¯å¢ƒä¸­ï¼Œå°è¯•ç›´æ¥è¯»å–æ–‡ä»¶\")\n",
    "    try:\n",
    "        df = pd.read_csv('processed_property_data.csv')\n",
    "        print(f\"âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼Œå…± {len(df)} æ¡è®°å½•\")\n",
    "    except:\n",
    "        print(\"âŒ æ— æ³•åŠ è½½æ•°æ®ï¼Œå°†åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®\")\n",
    "        # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®\n",
    "        n_samples = 500\n",
    "        df = pd.DataFrame({\n",
    "            'bedrooms': np.random.randint(1, 6, size=n_samples),\n",
    "            'bathrooms': np.random.randint(1, 4, size=n_samples),\n",
    "            'floor_size': np.random.randint(50, 300, size=n_samples),\n",
    "            'year_built': np.random.randint(1950, 2023, size=n_samples),\n",
    "            'suburb': np.random.choice(['Wellington Central', 'Lower Hutt', 'Upper Hutt', 'Porirua'], size=n_samples)\n",
    "        })\n",
    "        df['last_sold_price'] = df['bedrooms'] * 200000 + df['bathrooms'] * 100000 + df['floor_size'] * 2000 + np.random.normal(0, 100000, size=n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ç‰¹å¾å·¥ç¨‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç‰¹å¾å·¥ç¨‹\n",
    "print(\"ğŸ”„ å¼€å§‹ç‰¹å¾å·¥ç¨‹...\")\n",
    "\n",
    "# å¤„ç†ç±»åˆ«å‹ç‰¹å¾\n",
    "if 'suburb' in df.columns:\n",
    "    suburb_dummies = pd.get_dummies(df['suburb'], prefix='suburb')\n",
    "    df = pd.concat([df, suburb_dummies], axis=1)\n",
    "    df.drop('suburb', axis=1, inplace=True)\n",
    "    print(f\"âœ… å¯¹suburbè¿›è¡Œç‹¬çƒ­ç¼–ç ï¼Œæ–°å¢ {len(suburb_dummies.columns)} ä¸ªç‰¹å¾\")\n",
    "\n",
    "# æ·»åŠ æ–°ç‰¹å¾\n",
    "if 'year_built' in df.columns:\n",
    "    df['property_age'] = 2025 - df['year_built']\n",
    "    print(\"âœ… æ·»åŠ ç‰¹å¾: property_age (æˆ¿äº§å¹´é¾„)\")\n",
    "\n",
    "if 'bedrooms' in df.columns and 'bathrooms' in df.columns:\n",
    "    df['bedroom_bathroom_ratio'] = df['bedrooms'] / df['bathrooms'].replace(0, 1)\n",
    "    print(\"âœ… æ·»åŠ ç‰¹å¾: bedroom_bathroom_ratio (å§å®¤ä¸æµ´å®¤æ¯”ä¾‹)\")\n",
    "\n",
    "if 'last_sold_price' in df.columns and 'floor_size' in df.columns:\n",
    "    df['price_per_sqm'] = df['last_sold_price'] / df['floor_size'].replace(0, 1)\n",
    "    print(\"âœ… æ·»åŠ ç‰¹å¾: price_per_sqm (æ¯å¹³æ–¹ç±³ä»·æ ¼)\")\n",
    "\n",
    "if 'bedrooms' in df.columns and 'floor_size' in df.columns:\n",
    "    df['sqm_per_bedroom'] = df['floor_size'] / df['bedrooms'].replace(0, 1)\n",
    "    print(\"âœ… æ·»åŠ ç‰¹å¾: sqm_per_bedroom (æ¯å§å®¤å¹³æ–¹ç±³)\")\n",
    "\n",
    "# å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡\n",
    "y = df['last_sold_price']\n",
    "X = df.drop(['last_sold_price', 'id', 'created_at', 'updated_at', 'address', 'normalized_address', 'data'], axis=1, errors='ignore')\n",
    "\n",
    "# æ£€æŸ¥å¹¶åˆ é™¤éæ•°å€¼å‹ç‰¹å¾\n",
    "non_numeric_cols = X.select_dtypes(exclude=['int64', 'float64']).columns\n",
    "if len(non_numeric_cols) > 0:\n",
    "    print(f\"âš ï¸ åˆ é™¤éæ•°å€¼å‹ç‰¹å¾: {list(non_numeric_cols)}\")\n",
    "    X = X.drop(non_numeric_cols, axis=1)\n",
    "\n",
    "# æ ‡å‡†åŒ–ç‰¹å¾\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆï¼Œæœ€ç»ˆç‰¹å¾æ•°é‡: {X.shape[1]}\")\n",
    "print(f\"ğŸ“Š ç‰¹å¾åˆ—è¡¨: {list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "print(f\"âœ… è®­ç»ƒé›†å¤§å°: {X_train.shape[0]}ï¼Œæµ‹è¯•é›†å¤§å°: {X_test.shape[0]}\")\n",
    "\n",
    "# è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹\n",
    "print(\"ğŸ”„ è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹...\")\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# è¯„ä¼°æ¨¡å‹\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"âœ… æ¨¡å‹è¯„ä¼°:\")\n",
    "print(f\"   - å‡æ–¹è¯¯å·® (MSE): {mse:.2f}\")\n",
    "print(f\"   - å‡æ–¹æ ¹è¯¯å·® (RMSE): {rmse:.2f}\")\n",
    "print(f\"   - RÂ² åˆ†æ•°: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ç‰¹å¾é‡è¦æ€§åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç‰¹å¾é‡è¦æ€§åˆ†æ\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"ğŸ“Š ç‰¹å¾é‡è¦æ€§:\")\n",
    "display(feature_importance)\n",
    "\n",
    "# å¯è§†åŒ–ç‰¹å¾é‡è¦æ€§\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance.head(10))\n",
    "plt.title('Top 10 æœ€é‡è¦ç‰¹å¾')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. é¢„æµ‹æ ·æœ¬æˆ¿äº§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºæ ·æœ¬æˆ¿äº§\n",
    "sample_properties = pd.DataFrame([\n",
    "    {\n",
    "        'bedrooms': 3,\n",
    "        'bathrooms': 2,\n",
    "        'floor_size': 120,\n",
    "        'year_built': 2000,\n",
    "        'description': 'Wellington Centralçš„ä¸‰å±…å®¤æˆ¿äº§'\n",
    "    },\n",
    "    {\n",
    "        'bedrooms': 4,\n",
    "        'bathrooms': 2,\n",
    "        'floor_size': 180,\n",
    "        'year_built': 1990,\n",
    "        'description': 'Lower Huttçš„å››å±…å®¤æˆ¿äº§'\n",
    "    },\n",
    "    {\n",
    "        'bedrooms': 2,\n",
    "        'bathrooms': 1,\n",
    "        'floor_size': 80,\n",
    "        'year_built': 2010,\n",
    "        'description': 'Wellington Centralçš„ä¸¤å±…å®¤å…¬å¯“'\n",
    "    }\n",
    "])\n",
    "\n",
    "# ä¸ºæ ·æœ¬æˆ¿äº§æ·»åŠ ç›¸åŒçš„ç‰¹å¾\n",
    "if 'property_age' in X.columns:\n",
    "    sample_properties['property_age'] = 2025 - sample_properties['year_built']\n",
    "\n",
    "if 'bedroom_bathroom_ratio' in X.columns:\n",
    "    sample_properties['bedroom_bathroom_ratio'] = sample_properties['bedrooms'] / sample_properties['bathrooms']\n",
    "\n",
    "if 'sqm_per_bedroom' in X.columns:\n",
    "    sample_properties['sqm_per_bedroom'] = sample_properties['floor_size'] / sample_properties['bedrooms']\n",
    "\n",
    "# æ·»åŠ ç¼ºå¤±çš„ç‰¹å¾åˆ—\n",
    "for col in X.columns:\n",
    "    if col not in sample_properties.columns:\n",
    "        sample_properties[col] = 0\n",
    "\n",
    "# ç¡®ä¿åˆ—é¡ºåºä¸è®­ç»ƒæ•°æ®ç›¸åŒ\n",
    "sample_properties = sample_properties[X.columns]\n",
    "\n",
    "# æ ‡å‡†åŒ–æ ·æœ¬ç‰¹å¾\n",
    "sample_properties_scaled = scaler.transform(sample_properties)\n",
    "\n",
    "# é¢„æµ‹ä»·æ ¼\n",
    "predicted_prices = model.predict(sample_properties_scaled)\n",
    "\n",
    "# æ˜¾ç¤ºé¢„æµ‹ç»“æœ\n",
    "results = pd.DataFrame({\n",
    "    'æè¿°': ['Wellington Centralçš„ä¸‰å±…å®¤æˆ¿äº§', 'Lower Huttçš„å››å±…å®¤æˆ¿äº§', 'Wellington Centralçš„ä¸¤å±…å®¤å…¬å¯“'],\n",
    "    'é¢„æµ‹ä»·æ ¼ (NZD)': predicted_prices.round(2)\n",
    "})\n",
    "\n",
    "print(\"ğŸ“Š æ ·æœ¬æˆ¿äº§ä»·æ ¼é¢„æµ‹:\")\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ä¿å­˜æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿å­˜æ¨¡å‹\n",
    "import pickle\n",
    "from google.colab import files\n",
    "\n",
    "# ä¿å­˜æ¨¡å‹å’Œæ ‡å‡†åŒ–å™¨\n",
    "model_data = {\n",
    "    'model': model,\n",
    "    'scaler': scaler,\n",
    "    'feature_names': list(X.columns),\n",
    "    'training_date': pd.Timestamp.now().strftime('%Y-%m-%d'),\n",
    "    'r2_score': r2\n",
    "}\n",
    "\n",
    "with open('wellington_property_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model_data, f)\n",
    "\n",
    "# ä¸‹è½½æ¨¡å‹æ–‡ä»¶\n",
    "files.download('wellington_property_model.pkl')\n",
    "print(\"âœ… æ¨¡å‹å·²ä¿å­˜å¹¶å‡†å¤‡å¥½ä¸‹è½½\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
