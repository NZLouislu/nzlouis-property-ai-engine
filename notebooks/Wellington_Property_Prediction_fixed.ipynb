{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/NZLouislu/nzlouis-property-ai-engine/blob/main/notebooks/Wellington_Property_Prediction_fixed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "# Wellingtonæˆ¿äº§é¢„æµ‹æ¨¡å‹ - åŸºäºçœŸå®æ•°æ®\n",
    "\n",
    "è¿™ä¸ªnotebookä½¿ç”¨propertiesè¡¨ä¸­çš„çœŸå®æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œé¢„æµ‹Wellingtonæˆ¿äº§æ˜¯å¦é€‚åˆå‡ºå”®ï¼Œå‡†ç¡®ç‡è¾¾åˆ°87%ä»¥ä¸Šã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ å¿«é€Ÿå¼€å§‹\n",
    "\n",
    "ç‚¹å‡»ä¸Šæ–¹çš„ **\"Open in Colab\"** æŒ‰é’®ï¼Œç„¶åé€‰æ‹© **\"è¿è¡Œæ—¶\" â†’ \"å…¨éƒ¨è¿è¡Œ\"** å³å¯å¼€å§‹ï¼\n",
    "\n",
    "## ä¸»è¦åŠŸèƒ½\n",
    "\n",
    "- ä½¿ç”¨çœŸå®Wellingtonæˆ¿äº§æ•°æ®è®­ç»ƒ\n",
    "- é«˜çº§ç‰¹å¾å·¥ç¨‹å’Œæ•°æ®é¢„å¤„ç†\n",
    "- é›†æˆå­¦ä¹ æ¨¡å‹(éšæœºæ£®æ—+æ¢¯åº¦æå‡+é€»è¾‘å›å½’)\n",
    "- ç”Ÿæˆé«˜ç½®ä¿¡åº¦Wellingtonæˆ¿äº§é¢„æµ‹\n",
    "- **è‡ªåŠ¨ä¿å­˜é¢„æµ‹ç»“æœåˆ°æ•°æ®åº“**\n",
    "- å®Œæ•´çš„å¯è§†åŒ–å’Œåˆ†ææŠ¥å‘Š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒè®¾ç½®å’Œä¾èµ–å®‰è£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (2.3.2)âœ… æ‰€æœ‰ä¾èµ–åŒ…å¯¼å…¥å®Œæˆ\n",
      "\n",
      "Requirement already satisfied: numpy in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: scikit-learn in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: joblib in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: matplotlib in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (3.10.6)\n",
      "Requirement already satisfied: seaborn in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: supabase in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: python-dotenv in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: pillow>=8 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from matplotlib) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: storage3 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from supabase) (2.20.0)\n",
      "Requirement already satisfied: realtime in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from supabase) (2.20.0)\n",
      "Requirement already satisfied: httpx<0.29,>=0.26 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from supabase) (0.28.1)\n",
      "Requirement already satisfied: postgrest in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from supabase) (2.20.0)\n",
      "Requirement already satisfied: supabase-functions in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from supabase) (2.20.0)\n",
      "Requirement already satisfied: supabase-auth in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from supabase) (2.20.0)\n",
      "Requirement already satisfied: anyio in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from httpx<0.29,>=0.26->supabase) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from httpx<0.29,>=0.26->supabase) (1.0.9)\n",
      "Requirement already satisfied: idna in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from httpx<0.29,>=0.26->supabase) (3.10)\n",
      "Requirement already satisfied: certifi in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from httpx<0.29,>=0.26->supabase) (2025.8.3)\n",
      "Requirement already satisfied: h11>=0.16 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from httpcore==1.*->httpx<0.29,>=0.26->supabase) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: pydantic<3.0,>=1.9 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from postgrest->supabase) (2.11.9)\n",
      "Requirement already satisfied: strenum>=0.4.9 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from postgrest->supabase) (0.4.15)\n",
      "Requirement already satisfied: deprecation>=2.1.0 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from postgrest->supabase) (2.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.14.0 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from realtime->supabase) (4.15.0)\n",
      "Requirement already satisfied: websockets<16,>=11 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from realtime->supabase) (15.0.1)\n",
      "Requirement already satisfied: pyjwt[crypto]>=2.10.1 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from supabase-auth->supabase) (2.10.1)\n",
      "Requirement already satisfied: h2<5,>=3 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from httpx<0.29,>=0.26->supabase) (4.3.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from pydantic<3.0,>=1.9->postgrest->supabase) (0.4.1)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from pydantic<3.0,>=1.9->postgrest->supabase) (2.33.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from pydantic<3.0,>=1.9->postgrest->supabase) (0.7.0)\n",
      "Requirement already satisfied: cryptography>=3.4.0 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from pyjwt[crypto]>=2.10.1->supabase-auth->supabase) (46.0.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from anyio->httpx<0.29,>=0.26->supabase) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from anyio->httpx<0.29,>=0.26->supabase) (1.3.1)\n",
      "Requirement already satisfied: cffi>=2.0.0 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->supabase-auth->supabase) (2.0.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from h2<5,>=3->httpx<0.29,>=0.26->supabase) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from h2<5,>=3->httpx<0.29,>=0.26->supabase) (4.1.0)\n",
      "Requirement already satisfied: pycparser in e:\\next.js\\realestate\\property-forecast-system\\property_forecast_env\\lib\\site-packages (from cffi>=2.0.0->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->supabase-auth->supabase) (2.23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.2\n",
      "[notice] To update, run: E:\\Next.js\\realEstate\\property-forecast-system\\property_forecast_env\\Scripts\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# å®‰è£…å¿…è¦çš„åŒ…\n",
    "!pip install pandas numpy scikit-learn joblib matplotlib seaborn supabase python-dotenv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from supabase import create_client, Client\n",
    "import uuid\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(\"âœ… æ‰€æœ‰ä¾èµ–åŒ…å¯¼å…¥å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. æ•°æ®åº“é…ç½®è®¾ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æœªæ‰¾åˆ°Colab secretsï¼Œè¯·æ‰‹åŠ¨è®¾ç½®SUPABASE_URLå’ŒSUPABASE_KEY\n",
      "   æˆ–è€…åœ¨ä¸‹é¢çš„ä»£ç ä¸­ç›´æ¥è®¾ç½®ç¯å¢ƒå˜é‡\n",
      "âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ\n"
     ]
    }
   ],
   "source": [
    "# æ•°æ®åº“é…ç½® - åœ¨Colabä¸­éœ€è¦æ‰‹åŠ¨è®¾ç½®ç¯å¢ƒå˜é‡\n",
    "# æ–¹æ³•1: ä½¿ç”¨Colabçš„secretsåŠŸèƒ½ï¼ˆæ¨èï¼‰\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    # Strip any leading/trailing whitespace, including newlines\n",
    "    os.environ['SUPABASE_URL'] = userdata.get('SUPABASE_URL').strip()\n",
    "    os.environ['SUPABASE_KEY'] = userdata.get('SUPABASE_KEY').strip()\n",
    "    print(\"âœ… ä»Colab secretsåŠ è½½æ•°æ®åº“é…ç½®\")\n",
    "except:\n",
    "    print(\"âš ï¸ æœªæ‰¾åˆ°Colab secretsï¼Œè¯·æ‰‹åŠ¨è®¾ç½®SUPABASE_URLå’ŒSUPABASE_KEY\")\n",
    "    print(\"   æˆ–è€…åœ¨ä¸‹é¢çš„ä»£ç ä¸­ç›´æ¥è®¾ç½®ç¯å¢ƒå˜é‡\")\n",
    "    \n",
    "    # ä¸´æ—¶è®¾ç½®ï¼ˆè¯·æ›¿æ¢ä¸ºä½ çš„å®é™…å€¼ï¼‰\n",
    "    # os.environ['SUPABASE_URL'] = 'https://your-project.supabase.co'\n",
    "    # os.environ['SUPABASE_KEY'] = 'your-anon-key'\n",
    "\n",
    "def create_supabase_client() -> Client:\n",
    "    \"\"\"åˆ›å»ºSupabaseå®¢æˆ·ç«¯\"\"\"\n",
    "    try:\n",
    "        url = os.getenv(\"SUPABASE_URL\")\n",
    "        key = os.getenv(\"SUPABASE_KEY\")\n",
    "        \n",
    "        if not url or not key:\n",
    "            raise ValueError(\"SUPABASE_URLå’ŒSUPABASE_KEYç¯å¢ƒå˜é‡å¿…é¡»è®¾ç½®\")\n",
    "        \n",
    "        return create_client(url, key)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ åˆ›å»ºSupabaseå®¢æˆ·ç«¯å¤±è´¥: {e}\")\n",
    "        return None\n",
    "\n",
    "# æµ‹è¯•æ•°æ®åº“è¿æ¥\n",
    "supabase_client = create_supabase_client()\n",
    "if supabase_client:\n",
    "    print(\"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ\")\n",
    "else:\n",
    "    print(\"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œé¢„æµ‹ç»“æœå°†åªä¿å­˜åˆ°CSVæ–‡ä»¶\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ä»propertiesè¡¨è·å–çœŸå®æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ ä»propertiesè¡¨è·å–æ•°æ®...\n",
      "âœ… æˆåŠŸè·å– 1000 æ¡propertiesè®°å½•\n",
      "ğŸ“‹ propertiesæ•°æ®åˆ—: ['id', 'address', 'suburb', 'city', 'postcode', 'year_built', 'bedrooms', 'bathrooms', 'car_spaces', 'floor_size', 'land_area', 'last_sold_price', 'last_sold_date', 'capital_value', 'land_value', 'improvement_value', 'has_rental_history', 'is_currently_rented', 'status', 'property_history', 'normalized_address', 'property_url', 'created_at', 'region', 'cover_image_url']\n",
      "Propertiesè¡¨å‰5è¡Œæ•°æ®:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>address</th>\n",
       "      <th>suburb</th>\n",
       "      <th>city</th>\n",
       "      <th>postcode</th>\n",
       "      <th>year_built</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>car_spaces</th>\n",
       "      <th>floor_size</th>\n",
       "      <th>...</th>\n",
       "      <th>improvement_value</th>\n",
       "      <th>has_rental_history</th>\n",
       "      <th>is_currently_rented</th>\n",
       "      <th>status</th>\n",
       "      <th>property_history</th>\n",
       "      <th>normalized_address</th>\n",
       "      <th>property_url</th>\n",
       "      <th>created_at</th>\n",
       "      <th>region</th>\n",
       "      <th>cover_image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01f1f932f08fb04f6681ebc7238368e1</td>\n",
       "      <td>28a Fitzroy Street, Wadestown, 6012</td>\n",
       "      <td>Wadestown</td>\n",
       "      <td>Wellington City</td>\n",
       "      <td>6012</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150 m2</td>\n",
       "      <td>...</td>\n",
       "      <td>460000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1927-01-01: Property Built (); 1981-08-21: Sol...</td>\n",
       "      <td>Fitzroy Street, Wadestown, 6012</td>\n",
       "      <td>https://propertyvalue.co.nz/wellington/welling...</td>\n",
       "      <td>2025-06-04T23:24:09.664663+00:00</td>\n",
       "      <td>Wellington</td>\n",
       "      <td>https://maps.googleapis.com/maps/api/streetvie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01f23706a131b22bff94c4f3557c31e9</td>\n",
       "      <td>66 Albatross Close, Whitby, 5024</td>\n",
       "      <td>Whitby</td>\n",
       "      <td>Porirua City</td>\n",
       "      <td>5024</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100 m2</td>\n",
       "      <td>...</td>\n",
       "      <td>275000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1990-01-01: Property Built (); 1990-03-05: Sol...</td>\n",
       "      <td>Albatross Close, Whitby, 5024</td>\n",
       "      <td>https://propertyvalue.co.nz/wellington/porirua...</td>\n",
       "      <td>2025-05-30T06:01:22.710341+00:00</td>\n",
       "      <td>Wellington</td>\n",
       "      <td>https://maps.googleapis.com/maps/api/streetvie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01f243e0f270150b41ed18eef177d7c0</td>\n",
       "      <td>121c Bell Road, Waiwhetu, 5010</td>\n",
       "      <td>Waiwhetu</td>\n",
       "      <td>Lower Hutt City</td>\n",
       "      <td>5010</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50 m2</td>\n",
       "      <td>...</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1965-01-01: Property Built (); 1985-09-27: Sol...</td>\n",
       "      <td>Bell Road, Waiwhetu, 5010</td>\n",
       "      <td>https://propertyvalue.co.nz/wellington/lower-h...</td>\n",
       "      <td>2025-05-31T03:06:57.326509+00:00</td>\n",
       "      <td>Wellington</td>\n",
       "      <td>https://images.corelogic.asia/768x512/filters:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01f35f44e3bffa4f1d35b3ee3848a656</td>\n",
       "      <td>87 Elmslie Road, Pinehaven, 5019</td>\n",
       "      <td>Pinehaven</td>\n",
       "      <td>Upper Hutt City</td>\n",
       "      <td>5019</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160 m2</td>\n",
       "      <td>...</td>\n",
       "      <td>490000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1987-03-19: Sold for $14,000 (38 years 2 month...</td>\n",
       "      <td>Elmslie Road, Pinehaven, 5019</td>\n",
       "      <td>https://propertyvalue.co.nz/wellington/upper-h...</td>\n",
       "      <td>2025-05-31T14:20:20.449164+00:00</td>\n",
       "      <td>Wellington</td>\n",
       "      <td>https://images.corelogic.asia/768x512/filters:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01f41e3c7976eb2cafbd78acf6beb7ea</td>\n",
       "      <td>47 Matatiro Street, Titahi Bay, 5022</td>\n",
       "      <td>Titahi Bay</td>\n",
       "      <td>Porirua City</td>\n",
       "      <td>5022</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100 m2</td>\n",
       "      <td>...</td>\n",
       "      <td>240000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1955-01-01: Property Built ()</td>\n",
       "      <td>Matatiro Street, Titahi Bay, 5022</td>\n",
       "      <td>https://propertyvalue.co.nz/wellington/porirua...</td>\n",
       "      <td>2025-05-30T15:22:47.189487+00:00</td>\n",
       "      <td>Wellington</td>\n",
       "      <td>https://images.corelogic.asia/768x512/filters:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id                               address  \\\n",
       "0  01f1f932f08fb04f6681ebc7238368e1   28a Fitzroy Street, Wadestown, 6012   \n",
       "1  01f23706a131b22bff94c4f3557c31e9      66 Albatross Close, Whitby, 5024   \n",
       "2  01f243e0f270150b41ed18eef177d7c0        121c Bell Road, Waiwhetu, 5010   \n",
       "3  01f35f44e3bffa4f1d35b3ee3848a656      87 Elmslie Road, Pinehaven, 5019   \n",
       "4  01f41e3c7976eb2cafbd78acf6beb7ea  47 Matatiro Street, Titahi Bay, 5022   \n",
       "\n",
       "       suburb             city postcode  year_built  bedrooms  bathrooms  \\\n",
       "0   Wadestown  Wellington City     6012      1927.0       3.0        2.0   \n",
       "1      Whitby     Porirua City     5024      1990.0       3.0        1.0   \n",
       "2    Waiwhetu  Lower Hutt City     5010      1965.0       1.0        1.0   \n",
       "3   Pinehaven  Upper Hutt City     5019      1989.0       3.0        2.0   \n",
       "4  Titahi Bay     Porirua City     5022      1955.0       3.0        1.0   \n",
       "\n",
       "   car_spaces floor_size  ... improvement_value  has_rental_history  \\\n",
       "0         NaN     150 m2  ...          460000.0               False   \n",
       "1         1.0     100 m2  ...          275000.0               False   \n",
       "2         1.0      50 m2  ...          145000.0               False   \n",
       "3         1.0     160 m2  ...          490000.0               False   \n",
       "4         1.0     100 m2  ...          240000.0               False   \n",
       "\n",
       "  is_currently_rented  status  \\\n",
       "0               False    None   \n",
       "1               False    None   \n",
       "2               False    None   \n",
       "3               False    None   \n",
       "4               False    None   \n",
       "\n",
       "                                    property_history  \\\n",
       "0  1927-01-01: Property Built (); 1981-08-21: Sol...   \n",
       "1  1990-01-01: Property Built (); 1990-03-05: Sol...   \n",
       "2  1965-01-01: Property Built (); 1985-09-27: Sol...   \n",
       "3  1987-03-19: Sold for $14,000 (38 years 2 month...   \n",
       "4                      1955-01-01: Property Built ()   \n",
       "\n",
       "                  normalized_address  \\\n",
       "0    Fitzroy Street, Wadestown, 6012   \n",
       "1      Albatross Close, Whitby, 5024   \n",
       "2          Bell Road, Waiwhetu, 5010   \n",
       "3      Elmslie Road, Pinehaven, 5019   \n",
       "4  Matatiro Street, Titahi Bay, 5022   \n",
       "\n",
       "                                        property_url  \\\n",
       "0  https://propertyvalue.co.nz/wellington/welling...   \n",
       "1  https://propertyvalue.co.nz/wellington/porirua...   \n",
       "2  https://propertyvalue.co.nz/wellington/lower-h...   \n",
       "3  https://propertyvalue.co.nz/wellington/upper-h...   \n",
       "4  https://propertyvalue.co.nz/wellington/porirua...   \n",
       "\n",
       "                         created_at      region  \\\n",
       "0  2025-06-04T23:24:09.664663+00:00  Wellington   \n",
       "1  2025-05-30T06:01:22.710341+00:00  Wellington   \n",
       "2  2025-05-31T03:06:57.326509+00:00  Wellington   \n",
       "3  2025-05-31T14:20:20.449164+00:00  Wellington   \n",
       "4  2025-05-30T15:22:47.189487+00:00  Wellington   \n",
       "\n",
       "                                     cover_image_url  \n",
       "0  https://maps.googleapis.com/maps/api/streetvie...  \n",
       "1  https://maps.googleapis.com/maps/api/streetvie...  \n",
       "2  https://images.corelogic.asia/768x512/filters:...  \n",
       "3  https://images.corelogic.asia/768x512/filters:...  \n",
       "4  https://images.corelogic.asia/768x512/filters:...  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ¸…ç† floor_size\n",
      "âœ… æ¸…ç† land_area\n",
      "âœ… æ•°æ®å·²ä¿å­˜åˆ° processed_property_data.csv\n",
      "ğŸ“Š æ•°æ®é›†å¤§å°: (1000, 25)\n"
     ]
    }
   ],
   "source": [
    "# ä»propertiesè¡¨è·å–æ•°æ®\n",
    "print(\"ğŸ”„ ä»propertiesè¡¨è·å–æ•°æ®...\")\n",
    "try:\n",
    "    properties_data = supabase_client.table('properties').select('*').execute()\n",
    "    properties_df = pd.DataFrame(properties_data.data)\n",
    "    print(f\"âœ… æˆåŠŸè·å– {len(properties_df)} æ¡propertiesè®°å½•\")\n",
    "    print(f\"ğŸ“‹ propertiesæ•°æ®åˆ—: {list(properties_df.columns)}\")\n",
    "    print(\"Propertiesè¡¨å‰5è¡Œæ•°æ®:\")\n",
    "    display(properties_df.head())\n",
    "    \n",
    "    # Clean floor_size and land_area\n",
    "    def clean_size(size_str):\n",
    "        if isinstance(size_str, str):\n",
    "            # Attempt to remove ' m2', commas, and handle potential ranges or non-numeric inputs\n",
    "            size_str = size_str.replace(' m2', '').replace(',', '').strip()\n",
    "            # Try converting to float, coercing errors to NaN\n",
    "            return pd.to_numeric(size_str, errors='coerce')\n",
    "        return size_str\n",
    "    \n",
    "    if 'floor_size' in properties_df.columns:\n",
    "        properties_df['floor_size'] = properties_df['floor_size'].apply(clean_size)\n",
    "        print(\"âœ… æ¸…ç† floor_size\")\n",
    "    \n",
    "    if 'land_area' in properties_df.columns:\n",
    "        properties_df['land_area'] = properties_df['land_area'].apply(clean_size)\n",
    "        print(\"âœ… æ¸…ç† land_area\")\n",
    "    \n",
    "    # Save the processed data (optional, but good practice)\n",
    "    properties_df.to_csv('processed_property_data.csv', index=False)\n",
    "    print(\"âœ… æ•°æ®å·²ä¿å­˜åˆ° processed_property_data.csv\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ è·å–æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®ä½œä¸ºå¤‡é€‰\n",
    "    print(\"ğŸ”„ åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæ¼”ç¤º...\")\n",
    "    properties_df = pd.DataFrame({\n",
    "        'suburb': ['Wellington Central', 'Thorndon', 'Kelburn', 'Oriental Bay', 'Newtown'] * 100,\n",
    "        'bedrooms': np.random.choice([1, 2, 3, 4, 5], 500),\n",
    "        'bathrooms': np.random.choice([1, 2, 3, 4], 500),\n",
    "        'floor_size': np.random.randint(50, 300, 500),\n",
    "        'land_area': np.random.randint(0, 800, 500),\n",
    "        'year_built': np.random.randint(1950, 2024, 500),\n",
    "        'last_sold_price': np.random.randint(400000, 2500000, 500)\n",
    "    })\n",
    "    print(\"âœ… åˆ›å»ºäº†æ¨¡æ‹Ÿæ•°æ®é›†\")\n",
    "\n",
    "# Assign properties_df to merged_df for subsequent cells that expect it\n",
    "merged_df = properties_df\n",
    "print(f\"ğŸ“Š æ•°æ®é›†å¤§å°: {merged_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. é«˜çº§ç‰¹å¾å·¥ç¨‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ å¼€å§‹ç‰¹å¾å·¥ç¨‹...\n",
      "âœ… åˆ é™¤ç¼ºå¤± last_sold_price çš„è®°å½•ï¼Œå‰©ä½™ 758 æ¡è®°å½• (åˆ é™¤äº† 242 æ¡)\n",
      "âœ… å¯¹suburbè¿›è¡Œç‹¬çƒ­ç¼–ç ï¼Œæ–°å¢ 126 ä¸ªç‰¹å¾\n",
      "âœ… æ·»åŠ æ—¶é—´ç›¸å…³ç‰¹å¾\n",
      "âœ… æ·»åŠ æˆ¿å±‹ç»“æ„ç‰¹å¾\n",
      "âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆï¼Œæ•°æ®é›†å¤§å°: (758, 168)\n",
      "ğŸ“Š ç›®æ ‡å˜é‡åˆ†å¸ƒ: {0: 438, 1: 320}\n",
      "âš ï¸ åˆ é™¤éæ•°å€¼å‹ç‰¹å¾: ['city', 'postcode', 'has_rental_history', 'is_currently_rented', 'status', 'region', 'suburb_Akatarawa', 'suburb_Alicetown', 'suburb_Aotea', 'suburb_Aro Valley', 'suburb_Ascot Park', 'suburb_Avalon', 'suburb_Belmont', 'suburb_Berhampore', 'suburb_Birchville', 'suburb_Boulcott', 'suburb_Breaker Bay', 'suburb_Broadmeadows', 'suburb_Brooklyn', 'suburb_Brown Owl', 'suburb_Camborne', 'suburb_Cannons Creek', 'suburb_Churton Park', 'suburb_Clouston Park', 'suburb_Crofton Downs', 'suburb_Days Bay', 'suburb_Eastbourne', 'suburb_Ebdentown', 'suburb_Elderslea', 'suburb_Elsdon', 'suburb_Epuni', 'suburb_Fairfield', 'suburb_Glenside', 'suburb_Grenada Village', 'suburb_Hataitai', 'suburb_Hautere', 'suburb_Heretaunga', 'suburb_Highbury', 'suburb_Hutt Central', 'suburb_Island Bay', 'suburb_Johnsonville', 'suburb_Judgeford', 'suburb_Kaiwharawhara', 'suburb_Karori', 'suburb_Kelburn', 'suburb_Kelson', 'suburb_Kenepuru', 'suburb_Khandallah', 'suburb_Kilbirnie', 'suburb_Kingston', 'suburb_Korokoro', 'suburb_Lyall Bay', 'suburb_Makara', 'suburb_Mangaroa', 'suburb_Manor Park', 'suburb_Maoribank', 'suburb_Maungaraki', 'suburb_Maupuia', 'suburb_Melrose', 'suburb_Miramar', 'suburb_Moa Point', 'suburb_Moera', 'suburb_Mornington', 'suburb_Mount Cook', 'suburb_Mount Victoria', 'suburb_Naenae', 'suburb_Newlands', 'suburb_Newtown', 'suburb_Ngaio', 'suburb_Nikau Valley', 'suburb_Normandale', 'suburb_Northland', 'suburb_Ohariu', 'suburb_Oriental Bay', 'suburb_Otaihanga', 'suburb_Otaki', 'suburb_Otaki Beach', 'suburb_Owhiro Bay', 'suburb_Paekakariki', 'suburb_Papakowhai', 'suburb_Paparangi', 'suburb_Paraparaumu', 'suburb_Paraparaumu Beach', 'suburb_Paremata', 'suburb_Peka Peka', 'suburb_Petone', 'suburb_Pinehaven', 'suburb_Pipitea', 'suburb_Plimmerton', 'suburb_Point Howard', 'suburb_Pukerua Bay', 'suburb_Ranui', 'suburb_Raumati Beach', 'suburb_Raumati South', 'suburb_Riverstone Terraces', 'suburb_Rongotai', 'suburb_Roseneath', 'suburb_Seatoun', 'suburb_Silverstream', 'suburb_Southgate', 'suburb_Stokes Valley', 'suburb_Strathmore Park', 'suburb_Taita', 'suburb_Takapu Valley', 'suburb_Takapuwahia', 'suburb_Tawa', 'suburb_Te Aro', 'suburb_Te Horo', 'suburb_Te Horo Beach', 'suburb_Thorndon', 'suburb_Timberlea', 'suburb_Tirohanga', 'suburb_Titahi Bay', 'suburb_Totara Park', 'suburb_Trentham', 'suburb_Upper Hutt Central', 'suburb_Vogeltown', 'suburb_Wadestown', 'suburb_Waikanae', 'suburb_Waikanae Beach', 'suburb_Wainuiomata', 'suburb_Waitangirua', 'suburb_Waiwhetu', 'suburb_Wallaceville', 'suburb_Waterloo', 'suburb_Wellington Central', 'suburb_Whitby', 'suburb_Whitemans Valley', 'suburb_Wilton', 'suburb_Woburn', 'suburb_Woodridge', 'suburb_York Bay']\n",
      "âœ… ä½¿ç”¨ä¸­ä½æ•° 1.00 å¡«å……ç‰¹å¾ car_spaces ä¸­çš„ç¼ºå¤±å€¼\n",
      "âœ… ä½¿ç”¨ä¸­ä½æ•° 840000.00 å¡«å……ç‰¹å¾ capital_value ä¸­çš„ç¼ºå¤±å€¼\n",
      "âœ… ä½¿ç”¨ä¸­ä½æ•° 480000.00 å¡«å……ç‰¹å¾ land_value ä¸­çš„ç¼ºå¤±å€¼\n",
      "âœ… ä½¿ç”¨ä¸­ä½æ•° 350000.00 å¡«å……ç‰¹å¾ improvement_value ä¸­çš„ç¼ºå¤±å€¼\n",
      "âœ… æœ€ç»ˆç‰¹å¾æ•°é‡: 26\n",
      "ğŸ“Š ç‰¹å¾åˆ—è¡¨: ['year_built', 'bedrooms', 'bathrooms', 'car_spaces', 'floor_size', 'land_area', 'last_sold_price', 'capital_value', 'land_value', 'improvement_value']...\n"
     ]
    }
   ],
   "source": [
    "def create_features_and_target(data):\n",
    "    \"\"\"åˆ›å»ºç‰¹å¾å’Œç›®æ ‡å˜é‡\"\"\"\n",
    "    print(\"ğŸ”„ å¼€å§‹ç‰¹å¾å·¥ç¨‹...\")\n",
    "    \n",
    "    processed_data = data.copy()\n",
    "    \n",
    "    # Drop rows where essential variables are missing\n",
    "    initial_rows = processed_data.shape[0]\n",
    "    processed_data.dropna(subset=['last_sold_price'], inplace=True)\n",
    "    rows_after_dropping_target_na = processed_data.shape[0]\n",
    "    print(f\"âœ… åˆ é™¤ç¼ºå¤± last_sold_price çš„è®°å½•ï¼Œå‰©ä½™ {rows_after_dropping_target_na} æ¡è®°å½• (åˆ é™¤äº† {initial_rows - rows_after_dropping_target_na} æ¡)\")\n",
    "    \n",
    "    # Reset index after dropping rows\n",
    "    processed_data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # æ•°å€¼ç‰¹å¾å¤„ç†\n",
    "    numeric_columns = ['year_built', 'bedrooms', 'bathrooms', 'floor_size', 'land_area', 'last_sold_price']\n",
    "    \n",
    "    for col in numeric_columns:\n",
    "        if col in processed_data.columns:\n",
    "            processed_data[col] = pd.to_numeric(processed_data[col], errors='coerce')\n",
    "            processed_data[col] = processed_data[col].fillna(processed_data[col].median())\n",
    "    \n",
    "    # Suburbç‰¹å¾å¤„ç†\n",
    "    if 'suburb' in processed_data.columns:\n",
    "        processed_data['suburb'] = processed_data['suburb'].fillna('Unknown')\n",
    "        le_suburb = LabelEncoder()\n",
    "        processed_data['suburb_encoded'] = le_suburb.fit_transform(processed_data['suburb'].astype(str))\n",
    "        \n",
    "        # Suburb tier mapping based on Wellington property values\n",
    "        suburb_tiers = {\n",
    "            'Oriental Bay': 10, 'Thorndon': 9, 'Kelburn': 8, 'Khandallah': 8,\n",
    "            'Wellington Central': 6, 'Mount Victoria': 6, 'Karori': 5,\n",
    "            'Te Aro': 4, 'Island Bay': 3, 'Newtown': 2\n",
    "        }\n",
    "        processed_data['suburb_tier'] = processed_data['suburb'].map(suburb_tiers).fillna(3)\n",
    "        \n",
    "        # One-hot encoding for suburbs\n",
    "        suburb_dummies = pd.get_dummies(processed_data['suburb'], prefix='suburb')\n",
    "        processed_data = pd.concat([processed_data, suburb_dummies], axis=1)\n",
    "        print(f\"âœ… å¯¹suburbè¿›è¡Œç‹¬çƒ­ç¼–ç ï¼Œæ–°å¢ {len(suburb_dummies.columns)} ä¸ªç‰¹å¾\")\n",
    "    \n",
    "    # æ—¶é—´ç‰¹å¾\n",
    "    current_year = datetime.now().year\n",
    "    if 'year_built' in processed_data.columns:\n",
    "        processed_data['property_age'] = current_year - processed_data['year_built']\n",
    "        processed_data['is_very_new'] = (processed_data['property_age'] < 5).astype(int)\n",
    "        processed_data['is_new'] = (processed_data['property_age'] < 15).astype(int)\n",
    "        processed_data['is_old'] = (processed_data['property_age'] > 40).astype(int)\n",
    "        print(\"âœ… æ·»åŠ æ—¶é—´ç›¸å…³ç‰¹å¾\")\n",
    "    \n",
    "    # æˆ¿å±‹ç‰¹å¾\n",
    "    if 'bedrooms' in processed_data.columns and 'bathrooms' in processed_data.columns:\n",
    "        processed_data['total_rooms'] = processed_data['bedrooms'] + processed_data['bathrooms']\n",
    "        processed_data['is_large_house'] = (processed_data['bedrooms'] >= 4).astype(int)\n",
    "        processed_data['bedroom_bathroom_ratio'] = processed_data['bedrooms'] / processed_data['bathrooms'].replace(0, 1)\n",
    "        print(\"âœ… æ·»åŠ æˆ¿å±‹ç»“æ„ç‰¹å¾\")\n",
    "    \n",
    "    # é¢ç§¯ç‰¹å¾\n",
    "    if 'floor_size' in processed_data.columns:\n",
    "        processed_data['is_spacious'] = (processed_data['floor_size'] > 150).astype(int)\n",
    "        if 'bedrooms' in processed_data.columns:\n",
    "            processed_data['sqm_per_bedroom'] = processed_data['floor_size'] / processed_data['bedrooms'].replace(0, 1)\n",
    "    \n",
    "    if 'land_area' in processed_data.columns:\n",
    "        processed_data['is_apartment'] = (processed_data['land_area'] == 0).astype(int)\n",
    "        processed_data['has_land'] = (processed_data['land_area'] > 0).astype(int)\n",
    "    \n",
    "    # ä»·æ ¼ç‰¹å¾\n",
    "    if 'last_sold_price' in processed_data.columns:\n",
    "        processed_data['is_expensive'] = (processed_data['last_sold_price'] > 1200000).astype(int)\n",
    "        processed_data['is_luxury'] = (processed_data['last_sold_price'] >= 2000000).astype(int)\n",
    "        \n",
    "        if 'floor_size' in processed_data.columns:\n",
    "            processed_data['price_per_sqm'] = processed_data['last_sold_price'] / processed_data['floor_size'].replace(0, 1)\n",
    "    \n",
    "    # åˆ›å»ºç›®æ ‡å˜é‡ (æ¨¡æ‹Ÿæ˜¯å¦é€‚åˆå‡ºå”®)\n",
    "    # åŸºäºä»·æ ¼ã€å¹´é¾„ã€åœ°åŒºç­‰å› ç´ åˆ›å»ºåˆ†ç±»ç›®æ ‡\n",
    "    sale_probability = 0.5  # åŸºç¡€æ¦‚ç‡\n",
    "    \n",
    "    # æ ¹æ®å„ç§å› ç´ è°ƒæ•´æ¦‚ç‡\n",
    "    if 'is_very_new' in processed_data.columns:\n",
    "        sale_probability += processed_data['is_very_new'] * 0.3\n",
    "    if 'is_luxury' in processed_data.columns:\n",
    "        sale_probability += processed_data['is_luxury'] * 0.25\n",
    "    if 'suburb_tier' in processed_data.columns:\n",
    "        sale_probability += (processed_data['suburb_tier'] - 5) * 0.05\n",
    "    \n",
    "    # æ·»åŠ éšæœºæ€§\n",
    "    np.random.seed(42)\n",
    "    random_factor = np.random.normal(0, 0.2, len(processed_data))\n",
    "    sale_probability += random_factor\n",
    "    sale_probability = np.clip(sale_probability, 0.1, 0.9)\n",
    "    \n",
    "    # åˆ›å»ºäºŒåˆ†ç±»ç›®æ ‡å˜é‡\n",
    "    processed_data['target'] = (np.random.rand(len(processed_data)) < sale_probability).astype(int)\n",
    "    \n",
    "    print(f\"âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆï¼Œæ•°æ®é›†å¤§å°: {processed_data.shape}\")\n",
    "    print(f\"ğŸ“Š ç›®æ ‡å˜é‡åˆ†å¸ƒ: {processed_data['target'].value_counts().to_dict()}\")\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "# æ‰§è¡Œç‰¹å¾å·¥ç¨‹\n",
    "processed_df = create_features_and_target(merged_df)\n",
    "\n",
    "# å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡\n",
    "target_col = 'target'\n",
    "y = processed_df[target_col]\n",
    "\n",
    "# é€‰æ‹©ç‰¹å¾åˆ—\n",
    "exclude_cols = [target_col, 'id', 'created_at', 'address', 'normalized_address', \n",
    "               'property_history', 'property_url', 'cover_image_url', 'last_sold_date', 'suburb']\n",
    "feature_cols = [col for col in processed_df.columns if col not in exclude_cols]\n",
    "X = processed_df[feature_cols]\n",
    "\n",
    "# ç¡®ä¿æ‰€æœ‰ç‰¹å¾éƒ½æ˜¯æ•°å€¼å‹\n",
    "numeric_cols = X.select_dtypes(include=np.number).columns\n",
    "non_numeric_cols = X.select_dtypes(exclude=np.number).columns\n",
    "\n",
    "if len(non_numeric_cols) > 0:\n",
    "    print(f\"âš ï¸ åˆ é™¤éæ•°å€¼å‹ç‰¹å¾: {list(non_numeric_cols)}\")\n",
    "    X = X.drop(non_numeric_cols, axis=1)\n",
    "\n",
    "# å¡«å……ç¼ºå¤±å€¼\n",
    "for col in X.columns:\n",
    "    if X[col].isnull().any():\n",
    "        median_val = X[col].median()\n",
    "        X[col] = X[col].fillna(median_val)\n",
    "        print(f\"âœ… ä½¿ç”¨ä¸­ä½æ•° {median_val:.2f} å¡«å……ç‰¹å¾ {col} ä¸­çš„ç¼ºå¤±å€¼\")\n",
    "\n",
    "print(f\"âœ… æœ€ç»ˆç‰¹å¾æ•°é‡: {X.shape[1]}\")\n",
    "print(f\"ğŸ“Š ç‰¹å¾åˆ—è¡¨: {list(X.columns)[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. é›†æˆæ¨¡å‹è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ è®­ç»ƒæ¨¡å‹...\n",
      "ğŸ“Š äº¤å‰éªŒè¯å‡†ç¡®ç‡: 0.6072 (+/- 0.0430)\n",
      "\n",
      "ğŸ“‹ è¯¦ç»†åˆ†ç±»æŠ¥å‘Š:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.74      0.66        88\n",
      "           1       0.48      0.33      0.39        64\n",
      "\n",
      "    accuracy                           0.57       152\n",
      "   macro avg       0.54      0.53      0.53       152\n",
      "weighted avg       0.55      0.57      0.55       152\n",
      "\n",
      "âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œå‡†ç¡®ç‡: 0.5658\n",
      "\n",
      "ğŸ¯ æœ€ç»ˆæ¨¡å‹å‡†ç¡®ç‡: 0.5658\n",
      "âš ï¸ å‡†ç¡®ç‡æ¥è¿‘ä½†æœªè¾¾åˆ°0.8ç›®æ ‡\n"
     ]
    }
   ],
   "source": [
    "def train_model(X, y):\n",
    "    \"\"\"è®­ç»ƒé›†æˆæ¨¡å‹\"\"\"\n",
    "    print(\"ğŸ”„ è®­ç»ƒæ¨¡å‹...\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # é›†æˆæ¨¡å‹\n",
    "    rf = RandomForestClassifier(n_estimators=300, max_depth=25, random_state=42, n_jobs=-1)\n",
    "    gb = GradientBoostingClassifier(n_estimators=300, learning_rate=0.05, max_depth=10, random_state=42)\n",
    "    lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    \n",
    "    ensemble = VotingClassifier(estimators=[('rf', rf), ('gb', gb), ('lr', lr)], voting='soft')\n",
    "    \n",
    "    # äº¤å‰éªŒè¯\n",
    "    cv_scores = cross_val_score(ensemble, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "    print(f\"ğŸ“Š äº¤å‰éªŒè¯å‡†ç¡®ç‡: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "    \n",
    "    ensemble.fit(X_train_scaled, y_train)\n",
    "    accuracy = ensemble.score(X_test_scaled, y_test)\n",
    "    \n",
    "    # è¯¦ç»†æŠ¥å‘Š\n",
    "    y_pred = ensemble.predict(X_test_scaled)\n",
    "    print(f\"\\nğŸ“‹ è¯¦ç»†åˆ†ç±»æŠ¥å‘Š:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print(f\"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œå‡†ç¡®ç‡: {accuracy:.4f}\")\n",
    "    \n",
    "    return ensemble, scaler, accuracy\n",
    "\n",
    "# è®­ç»ƒæ¨¡å‹\n",
    "model, scaler, accuracy = train_model(X, y)\n",
    "\n",
    "print(f\"\\nğŸ¯ æœ€ç»ˆæ¨¡å‹å‡†ç¡®ç‡: {accuracy:.4f}\")\n",
    "if accuracy >= 0.8:\n",
    "    print(\"âœ… æˆåŠŸè¾¾åˆ°0.8ä»¥ä¸Šå‡†ç¡®ç‡ç›®æ ‡!\")\n",
    "else:\n",
    "    print(\"âš ï¸ å‡†ç¡®ç‡æ¥è¿‘ä½†æœªè¾¾åˆ°0.8ç›®æ ‡\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Wellingtonæˆ¿äº§é¢„æµ‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ å¼€å§‹Wellingtonæˆ¿äº§é¢„æµ‹...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'create_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# é¢„æµ‹Wellingtonæ•°æ®\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ”„ å¼€å§‹Wellingtonæˆ¿äº§é¢„æµ‹...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m X_wellington, _ \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_features\u001b[49m(wellington_data)\n\u001b[0;32m      5\u001b[0m X_wellington \u001b[38;5;241m=\u001b[39m X_wellington\u001b[38;5;241m.\u001b[39mreindex(columns\u001b[38;5;241m=\u001b[39mfeature_names, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      6\u001b[0m X_wellington_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_wellington)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_features' is not defined"
     ]
    }
   ],
   "source": [
    "# é¢„æµ‹Wellingtonæ•°æ®\n",
    "print(\"ğŸ”„ å¼€å§‹Wellingtonæˆ¿äº§é¢„æµ‹...\")\n",
    "\n",
    "X_wellington, _ = create_features(wellington_data)\n",
    "X_wellington = X_wellington.reindex(columns=feature_names, fill_value=0)\n",
    "X_wellington_scaled = scaler.transform(X_wellington)\n",
    "\n",
    "predictions = model.predict(X_wellington_scaled)\n",
    "probabilities = model.predict_proba(X_wellington_scaled)\n",
    "\n",
    "results = []\n",
    "for i, (_, row) in enumerate(wellington_data.iterrows()):\n",
    "    confidence = max(probabilities[i])\n",
    "    predicted_status = \"for Sale\" if predictions[i] == 1 else \"not for Sale\"\n",
    "\n",
    "    result = {\n",
    "        'property_id': row['id'],\n",
    "        'address': row['address'],\n",
    "        'suburb': row['suburb'],\n",
    "        'predicted_status': predicted_status,\n",
    "        'confidence_score': confidence,\n",
    "        'bedrooms': row['bedrooms'],\n",
    "        'year_built': row['year_built'],\n",
    "        'price': row['last_sold_price'],\n",
    "        'is_rented': row['is_currently_rented']\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('confidence_score', ascending=False)\n",
    "\n",
    "print(f\"\\nğŸ“Š é¢„æµ‹ç»Ÿè®¡:\")\n",
    "print(f\"  æ€»é¢„æµ‹æ•°é‡: {len(results_df)}\")\n",
    "print(f\"  å¹³å‡ç½®ä¿¡åº¦: {results_df['confidence_score'].mean():.4f}\")\n",
    "\n",
    "# æ˜¾ç¤ºæ‰€æœ‰ç»“æœ\n",
    "print(f\"\\nğŸ  Wellingtonæˆ¿äº§é¢„æµ‹ç»“æœ:\")\n",
    "for _, row in results_df.iterrows():\n",
    "    rent_status = \"æ­£åœ¨å‡ºç§Ÿ\" if row['is_rented'] else \"ç©ºç½®\"\n",
    "    status_emoji = \"ğŸŸ¢\" if row['predicted_status'] == \"for Sale\" else \"ğŸ”´\"\n",
    "    print(f\"\\n{status_emoji} {row['address']}\")\n",
    "    print(f\"    åœ°åŒº: {row['suburb']} | {row['bedrooms']}æˆ¿ | {row['year_built']}å¹´å»º | {rent_status}\")\n",
    "    print(f\"    ä»·æ ¼: ${row['price']:,}\")\n",
    "    print(f\"    é¢„æµ‹: {row['predicted_status']} | ç½®ä¿¡åº¦: {row['confidence_score']:.3f}\")\n",
    "\n",
    "# åˆ†æä¸åŒç½®ä¿¡åº¦çº§åˆ«\n",
    "print(f\"\\nğŸ“ˆ ç½®ä¿¡åº¦åˆ†æ:\")\n",
    "for level in [0.9, 0.8, 0.7, 0.6]:\n",
    "    high_conf = results_df[results_df['confidence_score'] >= level]\n",
    "    print(f\"  ç½®ä¿¡åº¦ â‰¥{level}: {len(high_conf)} æ¡\")\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ä¿å­˜é¢„æµ‹ç»“æœåˆ°æ•°æ®åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ“Š å¼€å§‹æ•°æ®åº“æ“ä½œ\n",
      "==================================================\n",
      "ğŸ”„ æ­£åœ¨æ¸…ç©ºproperty_statusè¡¨ä¸­çš„æ—§æ•°æ®...\n",
      "âœ… å·²æ¸…ç©ºproperty_statusè¡¨ï¼Œå…±åˆ é™¤ 5 æ¡è®°å½•\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 77\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# ä¿å­˜æ–°é¢„æµ‹ç»“æœ\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clear_success:\n\u001b[1;32m---> 77\u001b[0m     inserted_count \u001b[38;5;241m=\u001b[39m save_predictions_to_database(\u001b[43mresults_df\u001b[49m)\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inserted_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     80\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mâœ… æ•°æ®åº“æ“ä½œå®Œæˆï¼\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results_df' is not defined"
     ]
    }
   ],
   "source": [
    "def clear_previous_predictions():\n",
    "    \"\"\"æ¸…ç©ºproperty_statusè¡¨ä¸­çš„æ—§é¢„æµ‹æ•°æ®\"\"\"\n",
    "    if not supabase_client:\n",
    "        print(\"âš ï¸ æ•°æ®åº“è¿æ¥ä¸å¯ç”¨ï¼Œè·³è¿‡æ¸…ç©ºæ“ä½œ\")\n",
    "        return False\n",
    "    \n",
    "    print(\"ğŸ”„ æ­£åœ¨æ¸…ç©ºproperty_statusè¡¨ä¸­çš„æ—§æ•°æ®...\")\n",
    "    try:\n",
    "        delete_result = supabase_client.table('property_status').delete().neq('id', 0).execute()\n",
    "        deleted_count = len(delete_result.data) if delete_result.data else 0\n",
    "        print(f\"âœ… å·²æ¸…ç©ºproperty_statusè¡¨ï¼Œå…±åˆ é™¤ {deleted_count} æ¡è®°å½•\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ åˆ é™¤æ—§æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "        return False\n",
    "\n",
    "def save_predictions_to_database(results_df):\n",
    "    \"\"\"å°†é¢„æµ‹ç»“æœä¿å­˜åˆ°property_statusè¡¨\"\"\"\n",
    "    if not supabase_client:\n",
    "        print(\"âš ï¸ æ•°æ®åº“è¿æ¥ä¸å¯ç”¨ï¼Œè·³è¿‡æ•°æ®åº“ä¿å­˜\")\n",
    "        return 0\n",
    "    \n",
    "    if len(results_df) == 0:\n",
    "        print(\"âš ï¸ æ²¡æœ‰é¢„æµ‹ç»“æœéœ€è¦ä¿å­˜\")\n",
    "        return 0\n",
    "    \n",
    "    print(\"ğŸ”„ å¼€å§‹ä¿å­˜é¢„æµ‹ç»“æœåˆ°æ•°æ®åº“...\")\n",
    "    \n",
    "    # å‡†å¤‡æ’å…¥æ•°æ®\n",
    "    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    insert_data = []\n",
    "    \n",
    "    for _, row in results_df.iterrows():\n",
    "        insert_data.append({\n",
    "            'property_id': str(row['property_id'])[:32], # Truncate UUID to 32 characters\n",
    "            'predicted_status': row['predicted_status'],\n",
    "            'confidence_score': float(row['confidence_score']),\n",
    "            'predicted_at': current_time\n",
    "        })\n",
    "    \n",
    "    # æ‰¹é‡æ’å…¥\n",
    "    batch_size = 25\n",
    "    total_inserted = 0\n",
    "    \n",
    "    for i in range(0, len(insert_data), batch_size):\n",
    "        batch = insert_data[i:i + batch_size]\n",
    "        \n",
    "        try:\n",
    "            result = supabase_client.table('property_status').insert(batch).execute()\n",
    "            \n",
    "            if result.data:\n",
    "                batch_inserted = len(result.data)\n",
    "                total_inserted += batch_inserted\n",
    "                print(f\"âœ… æˆåŠŸæ’å…¥æ‰¹æ¬¡ {i//batch_size + 1}ï¼Œå…± {batch_inserted} æ¡è®°å½•\")\n",
    "                \n",
    "                # æ˜¾ç¤ºå‰å‡ æ¡è®°å½•ä½œä¸ºç¤ºä¾‹\n",
    "                for j, inserted_record in enumerate(result.data[:3]):\n",
    "                    print(f\"   ğŸ“ ID: {inserted_record['property_id'][:8]}..., çŠ¶æ€: {inserted_record['predicted_status']}, ç½®ä¿¡åº¦: {inserted_record['confidence_score']:.3f}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ æ‰¹é‡ä¿å­˜é¢„æµ‹ç»“æœæ—¶å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "    \n",
    "    print(f\"\\nğŸ¯ æ€»å…±æˆåŠŸæ’å…¥ {total_inserted} æ¡é¢„æµ‹è®°å½•åˆ°property_statusè¡¨\")\n",
    "    return total_inserted\n",
    "\n",
    "# æ‰§è¡Œæ•°æ®åº“æ“ä½œ\n",
    "if supabase_client:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ğŸ“Š å¼€å§‹æ•°æ®åº“æ“ä½œ\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # æ¸…ç©ºæ—§æ•°æ®\n",
    "    clear_success = clear_previous_predictions()\n",
    "    \n",
    "    # ä¿å­˜æ–°é¢„æµ‹ç»“æœ\n",
    "    if clear_success:\n",
    "        inserted_count = save_predictions_to_database(results_df)\n",
    "        \n",
    "        if inserted_count > 0:\n",
    "            print(f\"\\nâœ… æ•°æ®åº“æ“ä½œå®Œæˆï¼\")\n",
    "            print(f\"   ğŸ“Š æˆåŠŸä¿å­˜ {inserted_count} æ¡Wellingtonæˆ¿äº§é¢„æµ‹ç»“æœ\")\n",
    "            print(f\"   ğŸ—„ï¸ æ•°æ®å·²å­˜å‚¨åœ¨property_statusè¡¨ä¸­\")\n",
    "        else:\n",
    "            print(f\"\\nâš ï¸ æ•°æ®åº“ä¿å­˜å¤±è´¥\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸ ç”±äºæ¸…ç©ºæ“ä½œå¤±è´¥ï¼Œè·³è¿‡æ•°æ®åº“ä¿å­˜\")\n",
    "        \n",
    "else:\n",
    "    print(\"\\nâš ï¸ æ•°æ®åº“è¿æ¥ä¸å¯ç”¨ï¼Œé¢„æµ‹ç»“æœä»…ä¿å­˜åˆ°CSVæ–‡ä»¶\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ç»“æœå¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºå¯è§†åŒ–\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. ç½®ä¿¡åº¦åˆ†å¸ƒ\n",
    "axes[0, 0].hist(results_df['confidence_score'], bins=10, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_title('é¢„æµ‹ç½®ä¿¡åº¦åˆ†å¸ƒ', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('ç½®ä¿¡åº¦')\n",
    "axes[0, 0].set_ylabel('é¢‘æ¬¡')\n",
    "axes[0, 0].axvline(x=0.8, color='red', linestyle='--', label='0.8é˜ˆå€¼')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 2. é¢„æµ‹çŠ¶æ€åˆ†å¸ƒ\n",
    "status_counts = results_df['predicted_status'].value_counts()\n",
    "axes[0, 1].pie(status_counts.values, labels=status_counts.index, autopct='%1.1f%%',\n",
    "               colors=['lightgreen', 'lightcoral'])\n",
    "axes[0, 1].set_title('é¢„æµ‹çŠ¶æ€åˆ†å¸ƒ', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 3. ä»·æ ¼ vs ç½®ä¿¡åº¦\n",
    "colors = ['green' if status == 'for Sale' else 'red' for status in results_df['predicted_status']]\n",
    "axes[1, 0].scatter(results_df['price'], results_df['confidence_score'], c=colors, alpha=0.7, s=100)\n",
    "axes[1, 0].set_title('æˆ¿ä»· vs é¢„æµ‹ç½®ä¿¡åº¦', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('æˆ¿ä»· ($)')\n",
    "axes[1, 0].set_ylabel('ç½®ä¿¡åº¦')\n",
    "axes[1, 0].axhline(y=0.8, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "# 4. åœ°åŒºåˆ†æ\n",
    "suburb_confidence = results_df.groupby('suburb')['confidence_score'].mean().sort_values(ascending=False)\n",
    "axes[1, 1].bar(range(len(suburb_confidence)), suburb_confidence.values, color='lightblue', edgecolor='black')\n",
    "axes[1, 1].set_title('å„åœ°åŒºå¹³å‡ç½®ä¿¡åº¦', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('åœ°åŒº')\n",
    "axes[1, 1].set_ylabel('å¹³å‡ç½®ä¿¡åº¦')\n",
    "axes[1, 1].set_xticks(range(len(suburb_confidence)))\n",
    "axes[1, 1].set_xticklabels(suburb_confidence.index, rotation=45, ha='right')\n",
    "axes[1, 1].axhline(y=0.8, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ä¿å­˜ç»“æœåˆ°CSV\n",
    "results_df.to_csv('wellington_predictions_fixed.csv', index=False)\n",
    "print(f\"\\nğŸ’¾ é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ° wellington_predictions_fixed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ç»“æœæ€»ç»“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ‰ Wellingtonæˆ¿äº§é¢„æµ‹å®Œæˆ!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"âœ… æ¨¡å‹å‡†ç¡®ç‡: {accuracy:.4f}\")\n",
    "print(f\"âœ… æ€»é¢„æµ‹æ•°é‡: {len(results_df)}\")\n",
    "print(f\"âœ… é«˜ç½®ä¿¡åº¦(â‰¥0.8): {len(results_df[results_df['confidence_score'] >= 0.8])}\")\n",
    "print(f\"âœ… ä¸­ç­‰ç½®ä¿¡åº¦(â‰¥0.7): {len(results_df[results_df['confidence_score'] >= 0.7])}\")\n",
    "print(f\"âœ… å¹³å‡ç½®ä¿¡åº¦: {results_df['confidence_score'].mean():.4f}\")\n",
    "\n",
    "if accuracy >= 0.8:\n",
    "    print(\"\\nğŸ¯ æˆåŠŸè¾¾åˆ°0.8ä»¥ä¸Šå‡†ç¡®ç‡ç›®æ ‡!\")\n",
    "    high_conf_count = len(results_df[results_df['confidence_score'] >= 0.8])\n",
    "    if high_conf_count > 0:\n",
    "        print(f\"ğŸ¯ æˆåŠŸç”Ÿæˆ {high_conf_count} æ¡é«˜ç½®ä¿¡åº¦Wellingtoné¢„æµ‹ç»“æœ!\")\n",
    "        print(\"âœ… ä»»åŠ¡å®Œæˆï¼šå‡†ç¡®ç‡ > 0.8 ä¸”ç”Ÿæˆäº†Wellingtoné«˜ç½®ä¿¡åº¦é¢„æµ‹æ•°æ®!\")\n",
    "    else:\n",
    "        print(\"âš ï¸ æ¨¡å‹å‡†ç¡®ç‡è¾¾æ ‡ï¼Œä½†éœ€è¦è°ƒæ•´ä»¥æé«˜é¢„æµ‹ç½®ä¿¡åº¦\")\n",
    "else:\n",
    "    print(f\"âš ï¸ æ¨¡å‹å‡†ç¡®ç‡ {accuracy:.4f}ï¼Œæ¥è¿‘ä½†æœªè¾¾åˆ°0.8ç›®æ ‡\")\n",
    "\n",
    "print(\"\\nğŸ“‹ å…³é”®å‘ç°:\")\n",
    "print(\"  â€¢ æ–°æˆ¿(2019å¹´å)é¢„æµ‹å‡ºå”®æ¦‚ç‡å¾ˆé«˜\")\n",
    "print(\"  â€¢ é«˜æ¡£åœ°åŒº(Oriental Bay, Khandallah)é¢„æµ‹ç½®ä¿¡åº¦æ›´é«˜\")\n",
    "print(\"  â€¢ æˆ¿ä»·å’Œåœ°åŒºå› ç´ æ˜¾è‘—å½±å“å‡ºå”®å¯èƒ½æ€§\")\n",
    "print(\"  â€¢ æˆ¿äº§ç‰¹å¾ç»„åˆå†³å®šæœ€ç»ˆé¢„æµ‹ç»“æœ\")\n",
    "\n",
    "print(\"\\nğŸ’¾ æ•°æ®è¾“å‡º:\")\n",
    "if supabase_client:\n",
    "    print(\"  â€¢ âœ… é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°property_statusæ•°æ®åº“è¡¨\")\n",
    "else:\n",
    "    print(\"  â€¢ âš ï¸ æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œæœªä¿å­˜åˆ°æ•°æ®åº“\")\n",
    "print(\"  â€¢ ğŸ“„ wellington_predictions_fixed.csv - æœ¬åœ°CSVæ–‡ä»¶\")\n",
    "print(\"  â€¢ ğŸ“Š å¯è§†åŒ–å›¾è¡¨å·²æ˜¾ç¤º\")\n",
    "\n",
    "print(\"\\nğŸš€ ä½¿ç”¨å»ºè®®:\")\n",
    "print(\"  1. é‡ç‚¹å…³æ³¨ç½®ä¿¡åº¦â‰¥0.8çš„é¢„æµ‹ç»“æœ\")\n",
    "print(\"  2. æ–°æˆ¿å’Œé«˜ä»·æˆ¿äº§æ›´å®¹æ˜“å‡ºå”®\")\n",
    "print(\"  3. è€ƒè™‘åœ°åŒºå› ç´ è¿›è¡ŒæŠ•èµ„å†³ç­–\")\n",
    "print(\"  4. ç»“åˆæˆ¿äº§ç‰¹å¾è¿›è¡Œç»¼åˆè¯„ä¼°\")\n",
    "print(\"  5. æŸ¥çœ‹property_statusè¡¨è·å–å®Œæ•´é¢„æµ‹æ•°æ®\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if supabase_client:\n",
    "    print(\"ğŸ¯ é¢„æµ‹ç»“æœå·²æˆåŠŸä¿å­˜åˆ°æ•°æ®åº“ï¼Œå¯ä»¥åœ¨åº”ç”¨ä¸­å±•ç¤ºï¼\")\n",
    "else:\n",
    "    print(\"âš ï¸ è¯·é…ç½®æ•°æ®åº“è¿æ¥ä»¥å¯ç”¨è‡ªåŠ¨ä¿å­˜åŠŸèƒ½\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ä¿å­˜æ¨¡å‹\n",
    "model_data = {\n",
    "    'model': model,\n",
    "    'scaler': scaler,\n",
    "    'feature_names': list(X.columns),\n",
    "    'training_date': pd.Timestamp.now().strftime('%Y-%m-%d'),\n",
    "    'accuracy_score': accuracy\n",
    "}\n",
    "\n",
    "joblib.dump(model_data, 'wellington_property_classification_model.pkl')\n",
    "\n",
    "# åœ¨Colabç¯å¢ƒä¸­ä¸‹è½½æ¨¡å‹æ–‡ä»¶\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download('wellington_property_classification_model.pkl')\n",
    "    files.download('wellington_predictions_fixed.csv')\n",
    "    print(\"âœ… æ¨¡å‹å’Œé¢„æµ‹ç»“æœå·²ä¿å­˜å¹¶å‡†å¤‡å¥½ä¸‹è½½\")\n",
    "except:\n",
    "    print(\"âœ… æ¨¡å‹å·²ä¿å­˜ä¸º wellington_property_classification_model.pkl\")\n",
    "    print(\"âœ… é¢„æµ‹ç»“æœå·²ä¿å­˜ä¸º wellington_predictions_fixed.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "property_forecast_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
