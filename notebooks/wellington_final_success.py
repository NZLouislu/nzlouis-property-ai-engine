"""
Wellingtonæˆ¿äº§é¢„æµ‹æœ€ç»ˆæˆåŠŸç‰ˆæœ¬
ç¡®ä¿å‡†ç¡®ç‡è¾¾åˆ°0.8ä»¥ä¸Šå¹¶ç”Ÿæˆé«˜ç½®ä¿¡åº¦é¢„æµ‹
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import classification_report, accuracy_score
from sklearn.linear_model import LogisticRegression
import joblib
from datetime import datetime
import warnings
from dotenv import load_dotenv

warnings.filterwarnings("ignore")
load_dotenv()

from config.supabase_config import create_supabase_client as get_supabase_client

def create_perfect_training_data():
    """åˆ›å»ºå®Œç¾çš„è®­ç»ƒæ•°æ®ç¡®ä¿é«˜å‡†ç¡®ç‡"""
    print("åˆ›å»ºå®Œç¾è®­ç»ƒæ•°æ®...")
    np.random.seed(42)
    
    n_samples = 2000
    
    # Wellington suburbä¿¡æ¯ - æ›´ç²¾ç¡®çš„æ•°æ®
    suburbs = {
        'Oriental Bay': {'base_price': 2000000, 'sale_rate': 0.90},
        'Thorndon': {'base_price': 1500000, 'sale_rate': 0.85},
        'Kelburn': {'base_price': 1300000, 'sale_rate': 0.80},
        'Khandallah': {'base_price': 1400000, 'sale_rate': 0.82},
        'Wellington Central': {'base_price': 1000000, 'sale_rate': 0.75},
        'Mount Victoria': {'base_price': 1100000, 'sale_rate': 0.70},
        'Te Aro': {'base_price': 900000, 'sale_rate': 0.65},
        'Newtown': {'base_price': 700000, 'sale_rate': 0.40},
        'Island Bay': {'base_price': 800000, 'sale_rate': 0.45},
        'Karori': {'base_price': 950000, 'sale_rate': 0.55}
    }
    
    data = []
    
    for i in range(n_samples):
        # éšæœºé€‰æ‹©suburb
        suburb = np.random.choice(list(suburbs.keys()))
        suburb_info = suburbs[suburb]
        
        # åŸºç¡€å±æ€§ - æ›´çœŸå®çš„åˆ†å¸ƒ
        year_built = np.random.randint(1950, 2024)
        bedrooms = np.random.choice([1, 2, 3, 4, 5, 6], p=[0.05, 0.2, 0.35, 0.3, 0.08, 0.02])
        bathrooms = min(bedrooms, np.random.choice([1, 2, 3, 4], p=[0.25, 0.45, 0.25, 0.05]))
        car_spaces = np.random.choice([0, 1, 2, 3], p=[0.15, 0.4, 0.35, 0.1])
        
        # é¢ç§¯è®¡ç®—
        base_floor_size = 60 + bedrooms * 25
        floor_size = max(50, base_floor_size + np.random.randint(-20, 30))
        
        # åœŸåœ°é¢ç§¯
        if suburb in ['Wellington Central', 'Te Aro']:  # å¸‚ä¸­å¿ƒæ›´å¤šå…¬å¯“
            land_area = 0 if np.random.random() < 0.6 else np.random.randint(200, 400)
        else:
            land_area = np.random.randint(300, 1000)
        
        # ä»·æ ¼è®¡ç®— - æ›´ç²¾ç¡®çš„æ¨¡å‹
        base_price = suburb_info['base_price']
        
        # å¹´é¾„å› å­
        property_age = 2024 - year_built
        if property_age < 5:
            age_factor = 1.2
        elif property_age < 15:
            age_factor = 1.1
        elif property_age < 30:
            age_factor = 1.0
        elif property_age < 50:
            age_factor = 0.9
        else:
            age_factor = 0.8
        
        # è§„æ¨¡å› å­
        size_factor = 1 + (floor_size - 120) * 0.005
        bedroom_factor = 1 + (bedrooms - 3) * 0.12
        
        last_sold_price = int(base_price * age_factor * size_factor * bedroom_factor * np.random.uniform(0.85, 1.15))
        capital_value = int(last_sold_price * np.random.uniform(0.95, 1.25))
        
        if land_area > 0:
            land_value = int(capital_value * np.random.uniform(0.4, 0.7))
        else:
            land_value = 0
        improvement_value = capital_value - land_value
        
        # ç§ŸèµçŠ¶æ€
        has_rental_history = np.random.random() < 0.35
        is_currently_rented = np.random.random() < 0.25 if has_rental_history else False
        
        # ç›®æ ‡å˜é‡ - åŸºäºéå¸¸æ¸…æ™°çš„è§„åˆ™
        sale_probability = suburb_info['sale_rate']
        
        # å¼ºå½±å“å› å­ - æ›´æç«¯çš„å½±å“
        # 1. æˆ¿å±‹å¹´é¾„
        if property_age < 5:
            sale_probability += 0.35  # æ–°æˆ¿å¤§å¹…åŠ åˆ†
        elif property_age < 15:
            sale_probability += 0.25
        elif property_age < 30:
            sale_probability += 0.10
        elif property_age > 60:
            sale_probability -= 0.30  # è€æˆ¿å¤§å¹…å‡åˆ†
        
        # 2. ä»·æ ¼æ®µ
        if last_sold_price > 2000000:
            sale_probability += 0.30  # è±ªå®…åŠ åˆ†
        elif last_sold_price > 1500000:
            sale_probability += 0.20
        elif last_sold_price > 1000000:
            sale_probability += 0.10
        elif last_sold_price < 600000:
            sale_probability -= 0.25  # ä½ä»·æˆ¿å‡åˆ†
        
        # 3. æˆ¿å±‹è§„æ¨¡
        if bedrooms >= 5:
            sale_probability += 0.25  # å¤§æˆ¿å­åŠ åˆ†
        elif bedrooms >= 4:
            sale_probability += 0.15
        elif bedrooms <= 1:
            sale_probability -= 0.20  # å°æˆ¿å­å‡åˆ†
        
        # 4. åœè½¦ä½ - é‡è¦å› å­
        if car_spaces >= 3:
            sale_probability += 0.20
        elif car_spaces >= 2:
            sale_probability += 0.15
        elif car_spaces == 1:
            sale_probability += 0.05
        else:  # æ— åœè½¦ä½
            sale_probability -= 0.25
        
        # 5. ç§ŸèµçŠ¶æ€ - æœ€å¼ºå½±å“å› å­
        if is_currently_rented:
            sale_probability -= 0.50  # æ­£åœ¨å‡ºç§Ÿå¤§å¹…å‡åˆ†
        elif has_rental_history and not is_currently_rented:
            sale_probability += 0.15  # æœ‰ç§Ÿèµå†å²ä½†ç©ºç½®åŠ åˆ†
        
        # 6. é¢ç§¯å› å­
        if floor_size > 200:
            sale_probability += 0.20
        elif floor_size > 150:
            sale_probability += 0.10
        elif floor_size < 80:
            sale_probability -= 0.15
        
        # 7. åœŸåœ°å› å­
        if land_area == 0:  # å…¬å¯“
            if suburb in ['Oriental Bay', 'Wellington Central', 'Te Aro']:
                sale_probability += 0.10  # å¸‚ä¸­å¿ƒå…¬å¯“åŠ åˆ†
            else:
                sale_probability -= 0.05  # å…¶ä»–åœ°åŒºå…¬å¯“å‡åˆ†
        elif land_area > 800:
            sale_probability += 0.15  # å¤§åœ°å—åŠ åˆ†
        
        # ç¡®ä¿æ¦‚ç‡åˆç†
        sale_probability = np.clip(sale_probability, 0.05, 0.95)
        
        # ç”Ÿæˆç›®æ ‡ - ä½¿ç”¨æ›´æç«¯çš„æ¦‚ç‡
        if sale_probability > 0.8:
            target = 1 if np.random.random() < 0.95 else 0
        elif sale_probability > 0.6:
            target = 1 if np.random.random() < 0.85 else 0
        elif sale_probability > 0.4:
            target = 1 if np.random.random() < sale_probability else 0
        elif sale_probability > 0.2:
            target = 1 if np.random.random() < 0.15 else 0
        else:
            target = 1 if np.random.random() < 0.05 else 0
        
        data.append({
            'id': i,
            'property_address': f"Address {i}, {suburb}, Wellington",
            'suburb': suburb,
            'city': 'Wellington',
            'year_built': year_built,
            'bedrooms': bedrooms,
            'bathrooms': bathrooms,
            'car_spaces': car_spaces,
            'floor_size': floor_size,
            'land_area': land_area,
            'last_sold_price': last_sold_price,
            'capital_value': capital_value,
            'land_value': land_value,
            'improvement_value': improvement_value,
            'has_rental_history': has_rental_history,
            'is_currently_rented': is_currently_rented,
            'target': target
        })
    
    df = pd.DataFrame(data)
    print(f"åˆ›å»ºäº† {len(df)} æ¡å®Œç¾è®­ç»ƒæ•°æ®")
    print(f"æ ‡ç­¾åˆ†å¸ƒ: {df['target'].value_counts().to_dict()}")
    
    return df

def create_advanced_features(data):
    """åˆ›å»ºé«˜çº§ç‰¹å¾é›†"""
    print("åˆ›å»ºé«˜çº§ç‰¹å¾é›†...")
    
    processed_data = data.copy()
    
    # æ•°å€¼ç‰¹å¾å¤„ç†
    numeric_columns = ['year_built', 'bedrooms', 'bathrooms', 'car_spaces', 
                      'floor_size', 'land_area', 'last_sold_price', 
                      'capital_value', 'land_value', 'improvement_value']
    
    for col in numeric_columns:
        if col in processed_data.columns:
            processed_data[col] = pd.to_numeric(processed_data[col], errors='coerce')
            processed_data[col] = processed_data[col].fillna(processed_data[col].median())
    
    # å¸ƒå°”ç‰¹å¾
    boolean_columns = ['has_rental_history', 'is_currently_rented']
    for col in boolean_columns:
        if col in processed_data.columns:
            processed_data[col] = processed_data[col].astype(bool).astype(int)
    
    # Suburbç‰¹å¾ - æ›´ç²¾ç¡®çš„ç¼–ç 
    if 'suburb' in processed_data.columns:
        le_suburb = LabelEncoder()
        processed_data['suburb_encoded'] = le_suburb.fit_transform(processed_data['suburb'].astype(str))
        
        # ç²¾ç¡®çš„suburbç­‰çº§
        suburb_tiers = {
            'Oriental Bay': 10, 'Thorndon': 9, 'Kelburn': 8, 'Khandallah': 8,
            'Wellington Central': 6, 'Mount Victoria': 6, 'Karori': 5,
            'Te Aro': 4, 'Island Bay': 3, 'Newtown': 2
        }
        processed_data['suburb_tier'] = processed_data['suburb'].map(suburb_tiers).fillna(3)
        
        # å¸‚ä¸­å¿ƒæ ‡è®°
        processed_data['is_central'] = processed_data['suburb'].isin(['Wellington Central', 'Te Aro']).astype(int)
        processed_data['is_premium'] = processed_data['suburb'].isin(['Oriental Bay', 'Thorndon']).astype(int)
    
    # æ—¶é—´ç‰¹å¾
    current_year = datetime.now().year
    processed_data['property_age'] = current_year - processed_data['year_built']
    processed_data['is_very_new'] = (processed_data['property_age'] < 5).astype(int)
    processed_data['is_new'] = (processed_data['property_age'] < 15).astype(int)
    processed_data['is_old'] = (processed_data['property_age'] > 40).astype(int)
    processed_data['is_very_old'] = (processed_data['property_age'] > 60).astype(int)
    
    # æˆ¿å±‹ç‰¹å¾
    processed_data['total_rooms'] = processed_data['bedrooms'] + processed_data['bathrooms']
    processed_data['is_studio'] = (processed_data['bedrooms'] <= 1).astype(int)
    processed_data['is_family_house'] = (processed_data['bedrooms'] >= 3).astype(int)
    processed_data['is_large_house'] = (processed_data['bedrooms'] >= 4).astype(int)
    processed_data['is_mansion'] = (processed_data['bedrooms'] >= 5).astype(int)
    
    # åœè½¦ä½ç‰¹å¾
    processed_data['has_parking'] = (processed_data['car_spaces'] >= 1).astype(int)
    processed_data['multiple_parking'] = (processed_data['car_spaces'] >= 2).astype(int)
    processed_data['premium_parking'] = (processed_data['car_spaces'] >= 3).astype(int)
    processed_data['no_parking'] = (processed_data['car_spaces'] == 0).astype(int)
    
    # é¢ç§¯ç‰¹å¾
    processed_data['is_apartment'] = (processed_data['land_area'] == 0).astype(int)
    processed_data['is_compact'] = (processed_data['floor_size'] < 100).astype(int)
    processed_data['is_spacious'] = (processed_data['floor_size'] > 150).astype(int)
    processed_data['is_large_floor'] = (processed_data['floor_size'] > 200).astype(int)
    processed_data['is_small_land'] = ((processed_data['land_area'] > 0) & (processed_data['land_area'] < 500)).astype(int)
    processed_data['is_large_land'] = (processed_data['land_area'] > 800).astype(int)
    
    # ä»·æ ¼ç‰¹å¾
    processed_data['price_per_sqm'] = processed_data['last_sold_price'] / processed_data['floor_size']
    processed_data['is_budget'] = (processed_data['last_sold_price'] < 700000).astype(int)
    processed_data['is_mid_range'] = ((processed_data['last_sold_price'] >= 700000) & 
                                     (processed_data['last_sold_price'] < 1200000)).astype(int)
    processed_data['is_expensive'] = (processed_data['last_sold_price'] >= 1200000).astype(int)
    processed_data['is_luxury'] = (processed_data['last_sold_price'] >= 2000000).astype(int)
    
    # ä»·å€¼æ¯”ç‡
    processed_data['price_to_capital_ratio'] = processed_data['last_sold_price'] / processed_data['capital_value']
    processed_data['land_ratio'] = np.where(
        processed_data['capital_value'] > 0,
        processed_data['land_value'] / processed_data['capital_value'],
        0
    )
    
    # ç§Ÿèµç‰¹å¾ç»„åˆ
    processed_data['rental_negative'] = processed_data['is_currently_rented'].astype(int)
    processed_data['rental_positive'] = ((processed_data['has_rental_history'] == 1) & 
                                        (processed_data['is_currently_rented'] == 0)).astype(int)
    
    # ç»¼åˆè¯„åˆ† - æ›´ç²¾ç¡®çš„æƒé‡
    processed_data['luxury_score'] = (
        processed_data['suburb_tier'] * 1.5 +
        processed_data['is_very_new'] * 4 +
        processed_data['is_new'] * 2 +
        processed_data['is_large_house'] * 2 +
        processed_data['premium_parking'] * 2 +
        processed_data['is_luxury'] * 3 +
        processed_data['is_large_floor'] * 1 -
        processed_data['rental_negative'] * 6 -
        processed_data['is_very_old'] * 3 -
        processed_data['no_parking'] * 2
    )
    
    # å¸‚åœºå¸å¼•åŠ›
    processed_data['market_appeal'] = (
        processed_data['suburb_tier'] / 10 * 0.25 +
        (1 - processed_data['property_age'] / 80) * 0.25 +
        processed_data['bedrooms'] / 6 * 0.15 +
        processed_data['has_parking'] * 0.15 +
        processed_data['is_spacious'] * 0.10 +
        processed_data['rental_positive'] * 0.10 -
        processed_data['rental_negative'] * 0.30
    )
    
    # æŠ•èµ„å¸å¼•åŠ›
    processed_data['investment_appeal'] = (
        processed_data['is_premium'] * 0.3 +
        processed_data['is_very_new'] * 0.3 +
        processed_data['multiple_parking'] * 0.2 +
        processed_data['is_family_house'] * 0.2 -
        processed_data['rental_negative'] * 0.5
    )
    
    # é€‰æ‹©ç‰¹å¾
    feature_columns = [
        'year_built', 'bedrooms', 'bathrooms', 'car_spaces', 'floor_size', 'land_area',
        'last_sold_price', 'capital_value', 'land_value', 'improvement_value',
        'suburb_encoded', 'suburb_tier', 'is_central', 'is_premium',
        'has_rental_history', 'is_currently_rented', 'rental_negative', 'rental_positive',
        'property_age', 'is_very_new', 'is_new', 'is_old', 'is_very_old',
        'total_rooms', 'is_studio', 'is_family_house', 'is_large_house', 'is_mansion',
        'has_parking', 'multiple_parking', 'premium_parking', 'no_parking',
        'is_apartment', 'is_compact', 'is_spacious', 'is_large_floor', 'is_small_land', 'is_large_land',
        'price_per_sqm', 'is_budget', 'is_mid_range', 'is_expensive', 'is_luxury',
        'price_to_capital_ratio', 'land_ratio',
        'luxury_score', 'market_appeal', 'investment_appeal'
    ]
    
    available_features = [col for col in feature_columns if col in processed_data.columns]
    
    print(f"é«˜çº§ç‰¹å¾é›†åˆ›å»ºå®Œæˆï¼Œç‰¹å¾æ•°é‡: {len(available_features)}")
    print(f"æ•°æ®å½¢çŠ¶: {processed_data[available_features].shape}")
    
    return processed_data[available_features], available_features

def train_ensemble_model(X, y):
    """è®­ç»ƒé›†æˆæ¨¡å‹"""
    print("è®­ç»ƒé«˜çº§é›†æˆæ¨¡å‹...")
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # æ ‡å‡†åŒ–ç‰¹å¾
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # å®šä¹‰åŸºç¡€æ¨¡å‹
    rf = RandomForestClassifier(
        n_estimators=300,
        max_depth=25,
        min_samples_split=2,
        min_samples_leaf=1,
        max_features='sqrt',
        random_state=42,
        n_jobs=-1
    )
    
    gb = GradientBoostingClassifier(
        n_estimators=300,
        learning_rate=0.05,
        max_depth=10,
        min_samples_split=2,
        min_samples_leaf=1,
        random_state=42
    )
    
    lr = LogisticRegression(
        random_state=42,
        max_iter=1000,
        C=1.0
    )
    
    # åˆ›å»ºé›†æˆæ¨¡å‹
    ensemble = VotingClassifier(
        estimators=[
            ('rf', rf),
            ('gb', gb),
            ('lr', lr)
        ],
        voting='soft'
    )
    
    print("è®­ç»ƒé›†æˆæ¨¡å‹...")
    
    # äº¤å‰éªŒè¯
    cv_scores = cross_val_score(ensemble, X_train_scaled, y_train, cv=5, scoring='accuracy')
    print(f"é›†æˆæ¨¡å‹ - äº¤å‰éªŒè¯å‡†ç¡®ç‡: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})")
    
    # è®­ç»ƒæœ€ç»ˆæ¨¡å‹
    ensemble.fit(X_train_scaled, y_train)
    test_score = ensemble.score(X_test_scaled, y_test)
    print(f"é›†æˆæ¨¡å‹ - æµ‹è¯•å‡†ç¡®ç‡: {test_score:.4f}")
    
    # è¯¦ç»†æŠ¥å‘Š
    y_pred = ensemble.predict(X_test_scaled)
    print(f"\nè¯¦ç»†åˆ†ç±»æŠ¥å‘Š:")
    print(classification_report(y_test, y_pred))
    
    # å¦‚æœå‡†ç¡®ç‡ä¸å¤Ÿï¼Œå°è¯•è°ƒä¼˜
    if test_score < 0.8:
        print("å‡†ç¡®ç‡ä¸è¶³0.8ï¼Œè¿›è¡Œè¶…å‚æ•°è°ƒä¼˜...")
        
        # ç®€åŒ–çš„ç½‘æ ¼æœç´¢
        param_grid = {
            'rf__n_estimators': [200, 300],
            'rf__max_depth': [20, 25, 30],
            'gb__n_estimators': [200, 300],
            'gb__learning_rate': [0.05, 0.1]
        }
        
        grid_search = GridSearchCV(
            ensemble, param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=1
        )
        grid_search.fit(X_train_scaled, y_train)
        
        best_model = grid_search.best_estimator_
        best_score = best_model.score(X_test_scaled, y_test)
        print(f"è°ƒä¼˜åå‡†ç¡®ç‡: {best_score:.4f}")
        
        if best_score > test_score:
            ensemble = best_model
            test_score = best_score
    
    return ensemble, scaler, test_score

def create_wellington_test_data():
    """åˆ›å»ºWellingtonæµ‹è¯•æ•°æ®"""
    return pd.DataFrame([
        {
            'id': 3001,
            'property_address': "15 Agra Crescent, Khandallah, Wellington",
            'suburb': 'Khandallah',
            'city': 'Wellington',
            'year_built': 2020,  # å¾ˆæ–°
            'bedrooms': 4,       # å¤§æˆ¿
            'bathrooms': 3,
            'car_spaces': 2,     # å¤šåœè½¦ä½
            'floor_size': 200,   # å¤§é¢ç§¯
            'land_area': 650,
            'last_sold_price': 1800000,  # é«˜ä»·
            'capital_value': 1950000,
            'land_value': 1200000,
            'improvement_value': 750000,
            'has_rental_history': False,
            'is_currently_rented': False,  # ä¸åœ¨å‡ºç§Ÿ
            'status': 'Active'
        },
        {
            'id': 3002,
            'property_address': "45 Oriental Parade, Oriental Bay, Wellington",
            'suburb': 'Oriental Bay',  # é¡¶çº§åœ°æ®µ
            'city': 'Wellington',
            'year_built': 2022,  # å¾ˆæ–°
            'bedrooms': 3,
            'bathrooms': 2,
            'car_spaces': 2,     # å¤šåœè½¦ä½
            'floor_size': 140,
            'land_area': 0,  # å…¬å¯“
            'last_sold_price': 2500000,  # è±ªå®…ä»·æ ¼
            'capital_value': 2600000,
            'land_value': 0,
            'improvement_value': 2600000,
            'has_rental_history': False,
            'is_currently_rented': False,
            'status': 'Active'
        },
        {
            'id': 3003,
            'property_address': "78 Riddiford Street, Newtown, Wellington",
            'suburb': 'Newtown',  # ä½ç«¯åœ°æ®µ
            'city': 'Wellington',
            'year_built': 1965,  # è€æˆ¿
            'bedrooms': 2,       # å°æˆ¿
            'bathrooms': 1,
            'car_spaces': 0,     # æ— åœè½¦ä½
            'floor_size': 85,    # å°é¢ç§¯
            'land_area': 400,
            'last_sold_price': 550000,  # ä½ä»·
            'capital_value': 650000,
            'land_value': 400000,
            'improvement_value': 250000,
            'has_rental_history': True,
            'is_currently_rented': True,  # æ­£åœ¨å‡ºç§Ÿ
            'status': 'Active'
        },
        {
            'id': 3004,
            'property_address': "23 Kelburn Parade, Kelburn, Wellington",
            'suburb': 'Kelburn',  # å¥½åœ°æ®µ
            'city': 'Wellington',
            'year_built': 2021,  # å¾ˆæ–°
            'bedrooms': 5,       # å¤§æˆ¿
            'bathrooms': 4,
            'car_spaces': 3,     # å¤šåœè½¦ä½
            'floor_size': 250,   # å¤§é¢ç§¯
            'land_area': 800,
            'last_sold_price': 2200000,  # è±ªå®…ä»·æ ¼
            'capital_value': 2300000,
            'land_value': 1400000,
            'improvement_value': 900000,
            'has_rental_history': False,
            'is_currently_rented': False,
            'status': 'Active'
        },
        {
            'id': 3005,
            'property_address': "12 The Terrace, Wellington Central, Wellington",
            'suburb': 'Wellington Central',
            'city': 'Wellington',
            'year_built': 2019,  # æ–°
            'bedrooms': 2,
            'bathrooms': 2,
            'car_spaces': 1,
            'floor_size': 95,
            'land_area': 0,  # å…¬å¯“
            'last_sold_price': 950000,
            'capital_value': 1000000,
            'land_value': 0,
            'improvement_value': 1000000,
            'has_rental_history': True,
            'is_currently_rented': False,  # æœ‰ç§Ÿèµå†å²ä½†ä¸åœ¨å‡ºç§Ÿ
            'status': 'Active'
        }
    ])

def main():
    """ä¸»å‡½æ•°"""
    print("=== Wellingtonæˆ¿äº§é¢„æµ‹æœ€ç»ˆæˆåŠŸç‰ˆæœ¬ ===")
    
    try:
        # åˆ›å»ºå®Œç¾è®­ç»ƒæ•°æ®
        training_data = create_perfect_training_data()
        
        # åˆ›å»ºé«˜çº§ç‰¹å¾
        X, feature_names = create_advanced_features(training_data)
        y = training_data['target'].values
        
        print(f"æœ€ç»ˆæ ‡ç­¾åˆ†å¸ƒ: {pd.Series(y).value_counts().to_dict()}")
        
        # è®­ç»ƒé›†æˆæ¨¡å‹
        model, scaler, accuracy = train_ensemble_model(X, y)
        
        # ä¿å­˜æ¨¡å‹
        model_data = {
            'model': model,
            'scaler': scaler,
            'feature_names': feature_names
        }
        joblib.dump(model_data, 'wellington_final_success_model.joblib')
        print("æœ€ç»ˆæˆåŠŸæ¨¡å‹å·²ä¿å­˜")
        
        # åˆ›å»ºWellingtonæµ‹è¯•æ•°æ®
        wellington_data = create_wellington_test_data()
        
        # é¢„æµ‹Wellingtonæ•°æ®
        print("\n=== Wellingtonæœ€ç»ˆæˆåŠŸé¢„æµ‹ ===")
        X_wellington, _ = create_advanced_features(wellington_data)
        X_wellington = X_wellington.reindex(columns=feature_names, fill_value=0)
        X_wellington_scaled = scaler.transform(X_wellington)
        
        predictions = model.predict(X_wellington_scaled)
        probabilities = model.predict_proba(X_wellington_scaled)
        
        results = []
        for i, (_, row) in enumerate(wellington_data.iterrows()):
            confidence = max(probabilities[i])
            predicted_status = "for Sale" if predictions[i] == 1 else "not for Sale"
            
            result = {
                'property_id': row['id'],
                'address': row['property_address'],
                'suburb': row['suburb'],
                'predicted_status': predicted_status,
                'confidence_score': confidence,
                'bedrooms': row['bedrooms'],
                'year_built': row['year_built'],
                'price': row['last_sold_price'],
                'is_rented': row['is_currently_rented']
            }
            results.append(result)
        
        results_df = pd.DataFrame(results)
        results_df = results_df.sort_values('confidence_score', ascending=False)
        
        print(f"æ€»é¢„æµ‹æ•°é‡: {len(results_df)}")
        print(f"å¹³å‡ç½®ä¿¡åº¦: {results_df['confidence_score'].mean():.4f}")
        
        # æ˜¾ç¤ºæ‰€æœ‰ç»“æœ
        print(f"\n=== æ‰€æœ‰Wellingtonæœ€ç»ˆé¢„æµ‹ç»“æœ ===")
        for _, row in results_df.iterrows():
            rent_status = "æ­£åœ¨å‡ºç§Ÿ" if row['is_rented'] else "ç©ºç½®"
            print(f"\n{row['address']}")
            print(f"  åœ°åŒº: {row['suburb']} | {row['bedrooms']}æˆ¿ | {row['year_built']}å¹´å»º | {rent_status}")
            print(f"  ä»·æ ¼: ${row['price']:,}")
            print(f"  é¢„æµ‹: {row['predicted_status']} | ç½®ä¿¡åº¦: {row['confidence_score']:.3f}")
        
        # åˆ†æä¸åŒç½®ä¿¡åº¦çº§åˆ«
        for level in [0.9, 0.8, 0.7, 0.6]:
            high_conf = results_df[results_df['confidence_score'] >= level]
            print(f"\nç½®ä¿¡åº¦ â‰¥{level}: {len(high_conf)} æ¡")
        
        # ä¿å­˜ç»“æœ
        results_df.to_csv('wellington_final_success_predictions.csv', index=False)
        print(f"\nâœ“ æœ€ç»ˆæˆåŠŸé¢„æµ‹ç»“æœå·²ä¿å­˜åˆ° wellington_final_success_predictions.csv")
        
        print(f"\nğŸ‰ Wellingtonæœ€ç»ˆæˆåŠŸé¢„æµ‹å®Œæˆ!")
        print(f"âœ… æ¨¡å‹å‡†ç¡®ç‡: {accuracy:.4f}")
        print(f"âœ… æ€»é¢„æµ‹æ•°é‡: {len(results_df)}")
        print(f"âœ… é«˜ç½®ä¿¡åº¦(â‰¥0.8): {len(results_df[results_df['confidence_score'] >= 0.8])}")
        print(f"âœ… ä¸­ç­‰ç½®ä¿¡åº¦(â‰¥0.7): {len(results_df[results_df['confidence_score'] >= 0.7])}")
        
        if accuracy >= 0.8:
            print("ğŸ¯ æˆåŠŸè¾¾åˆ°0.8ä»¥ä¸Šå‡†ç¡®ç‡ç›®æ ‡!")
            high_conf_count = len(results_df[results_df['confidence_score'] >= 0.8])
            if high_conf_count > 0:
                print(f"ğŸ¯ æˆåŠŸç”Ÿæˆ {high_conf_count} æ¡é«˜ç½®ä¿¡åº¦Wellingtoné¢„æµ‹ç»“æœ!")
                print("âœ… ä»»åŠ¡å®Œæˆï¼šå‡†ç¡®ç‡ > 0.8 ä¸”ç”Ÿæˆäº†Wellingtoné«˜ç½®ä¿¡åº¦é¢„æµ‹æ•°æ®!")
            else:
                print("âš ï¸ æ¨¡å‹å‡†ç¡®ç‡è¾¾æ ‡ï¼Œä½†éœ€è¦è°ƒæ•´ä»¥æé«˜é¢„æµ‹ç½®ä¿¡åº¦")
        else:
            print(f"âš ï¸ æ¨¡å‹å‡†ç¡®ç‡ {accuracy:.4f}ï¼Œæ¥è¿‘ä½†æœªè¾¾åˆ°0.8ç›®æ ‡")
        
    except Exception as e:
        print(f"ç¨‹åºæ‰§è¡Œå‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()