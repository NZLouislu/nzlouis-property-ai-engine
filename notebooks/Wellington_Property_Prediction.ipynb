{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/NZLouislu/nzlouis-property-ai-engine/blob/main/notebooks/Wellington_Property_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wellington房产预测模型 - 基于真实数据\n",
    "\n",
    "这个notebook实现了一个高精度的Wellington房产预测模型，使用real_estate表中的真实数据进行训练，能够预测房产是否适合出售。\n",
    "\n",
    "## 🚀 快速开始\n",
    "点击上方的 **\"Open in Colab\"** 按钮，然后选择 **\"运行时\" → \"全部运行\"** 即可开始！\n",
    "\n",
    "## 主要功能\n",
    "- 从real_estate表获取真实训练数据\n",
    "- 高级特征工程\n",
    "- 集成学习模型(随机森林+梯度提升+逻辑回归)\n",
    "- 生成高置信度Wellington房产预测\n",
    "- 自动保存预测结果到数据库\n",
    "\n",
    "## 使用方法\n",
    "1. 点击上方的\"Open in Colab\"按钮\n",
    "2. 在Colab中设置Supabase凭据\n",
    "3. 选择\"运行时\" → \"全部运行\"\n",
    "4. 等待所有单元格执行完成\n",
    "5. 查看预测结果和可视化图表\n",
    "6. 预测结果将自动保存到property_status表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境设置和依赖安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装必要的包\n",
    "!pip install pandas numpy scikit-learn joblib matplotlib seaborn supabase python-dotenv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from supabase import create_client, Client\n",
    "import uuid\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(\"✅ 所有依赖包安装完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据库配置设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据库配置 - 在Colab中需要手动设置环境变量\n",
    "# 请在运行前设置你的Supabase凭据\n",
    "\n",
    "# 方法1: 直接设置（不推荐用于生产环境）\n",
    "# os.environ['SUPABASE_URL'] = 'your_supabase_url_here'\n",
    "# os.environ['SUPABASE_KEY'] = 'your_supabase_key_here'\n",
    "\n",
    "# 方法2: 使用Colab的secrets功能（推荐）\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    # Strip any leading/trailing whitespace, including newlines\n",
    "    os.environ['SUPABASE_URL'] = userdata.get('SUPABASE_URL').strip()\n",
    "    os.environ['SUPABASE_KEY'] = userdata.get('SUPABASE_KEY').strip()\n",
    "    print(\"✅ 从Colab secrets加载数据库配置\")\n",
    "except:\n",
    "    print(\"⚠️ 未找到Colab secrets，请手动设置SUPABASE_URL和SUPABASE_KEY\")\n",
    "    print(\"   或者在下面的代码中直接设置环境变量\")\n",
    "\n",
    "    # 临时设置（请替换为你的实际值）\n",
    "    # os.environ['SUPABASE_URL'] = 'https://your-project.supabase.co'\n",
    "    # os.environ['SUPABASE_KEY'] = 'your-anon-key'\n",
    "\n",
    "def create_supabase_client() -> Client:\n",
    "    \"\"\"创建Supabase客户端\"\"\"\n",
    "    try:\n",
    "        url = os.getenv(\"SUPABASE_URL\")\n",
    "        key = os.getenv(\"SUPABASE_KEY\")\n",
    "\n",
    "        if not url or not key:\n",
    "            raise ValueError(\"SUPABASE_URL和SUPABASE_KEY环境变量必须设置\")\n",
    "\n",
    "        return create_client(url, key)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 创建Supabase客户端失败: {e}\")\n",
    "        return None\n",
    "\n",
    "# 测试数据库连接\n",
    "supabase_client = create_supabase_client()\n",
    "if supabase_client:\n",
    "    print(\"✅ 数据库连接成功\")\n",
    "else:\n",
    "    print(\"❌ 数据库连接失败，预测结果将只保存到CSV文件\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 从real_estate表获取训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data_from_real_estate():\n",
    "    \"\"\"从real_estate表获取Wellington和Auckland的销售数据作为训练集\"\"\"\n",
    "    if not supabase_client:\n",
    "        print(\"❌ 数据库连接不可用，无法获取训练数据\")\n",
    "        return create_mock_training_data()\n",
    "    \n",
    "    print(\"🔄 从real_estate表获取训练数据...\")\n",
    "    \n",
    "    try:\n",
    "        # 获取所有数据\n",
    "        response = supabase_client.table('real_estate').select('*').execute()\n",
    "        \n",
    "        if not response.data:\n",
    "            print(\"⚠️ real_estate表中没有数据，将使用模拟数据\")\n",
    "            return create_mock_training_data()\n",
    "            \n",
    "        df = pd.DataFrame(response.data)\n",
    "        print(f\"✅ 从real_estate表获取了 {len(df)} 条记录\")\n",
    "        print(f\"📋 获取的列: {list(df.columns)}\")\n",
    "        \n",
    "        # 处理数据\n",
    "        processed_data = process_real_estate_data(df)\n",
    "        \n",
    "        if processed_data is None or len(processed_data) < 100:\n",
    "            print(\"⚠️ 处理后的数据不足，将使用模拟数据补充\")\n",
    "            mock_data = create_mock_training_data(500)\n",
    "            if processed_data is not None:\n",
    "                processed_data = pd.concat([processed_data, mock_data], ignore_index=True)\n",
    "            else:\n",
    "                processed_data = mock_data\n",
    "        \n",
    "        print(f\"✅ 最终训练数据: {len(processed_data)} 条记录\")\n",
    "        print(f\"📊 标签分布: {processed_data['target'].value_counts().to_dict()}\")\n",
    "        \n",
    "        return processed_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 获取训练数据时发生错误: {e}\")\n",
    "        print(\"⚠️ 将使用模拟数据进行训练\")\n",
    "        return create_mock_training_data()\n",
    "\n",
    "def process_real_estate_data(df):\n",
    "    \"\"\"处理real_estate表的数据，提取特征\"\"\"\n",
    "    if df is None or len(df) == 0:\n",
    "        return None\n",
    "    \n",
    "    print(\"🔄 处理real_estate数据...\")\n",
    "    \n",
    "    processed_data = df.copy()\n",
    "    \n",
    "    # 解析data字段中的JSON数据（如果存在）\n",
    "    if 'data' in processed_data.columns:\n",
    "        try:\n",
    "            data_features = []\n",
    "            \n",
    "            for idx, row in processed_data.iterrows():\n",
    "                try:\n",
    "                    if pd.notna(row['data']) and row['data']:\n",
    "                        if isinstance(row['data'], str):\n",
    "                            data_dict = json.loads(row['data'])\n",
    "                        else:\n",
    "                            data_dict = row['data']\n",
    "                        data_features.append(data_dict)\n",
    "                    else:\n",
    "                        data_features.append({})\n",
    "                except:\n",
    "                    data_features.append({})\n",
    "            \n",
    "            # 将JSON数据转换为DataFrame\n",
    "            data_df = pd.json_normalize(data_features)\n",
    "            \n",
    "            # 合并数据\n",
    "            processed_data = pd.concat([processed_data.reset_index(drop=True), data_df], axis=1)\n",
    "            print(f\"✅ 成功解析data字段，新增 {len(data_df.columns)} 个特征\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 解析data字段时发生错误: {e}\")\n",
    "    \n",
    "    # 筛选Wellington和Auckland的数据\n",
    "    wellington_auckland_data = None\n",
    "    \n",
    "    if 'normalized_location' in processed_data.columns:\n",
    "        wellington_auckland_data = processed_data[\n",
    "            processed_data['normalized_location'].str.contains('wellington|auckland', case=False, na=False)\n",
    "        ]\n",
    "        print(f\"✅ 从normalized_location筛选出Wellington和Auckland数据: {len(wellington_auckland_data)} 条\")\n",
    "    elif 'address' in processed_data.columns:\n",
    "        wellington_auckland_data = processed_data[\n",
    "            processed_data['address'].str.contains('wellington|auckland', case=False, na=False)\n",
    "        ]\n",
    "        print(f\"✅ 从address字段筛选出Wellington和Auckland数据: {len(wellington_auckland_data)} 条\")\n",
    "    else:\n",
    "        wellington_auckland_data = processed_data\n",
    "        print(f\"⚠️ 无法筛选地区，使用所有数据: {len(wellington_auckland_data)} 条\")\n",
    "    \n",
    "    if len(wellington_auckland_data) == 0:\n",
    "        print(\"❌ 没有找到Wellington或Auckland的数据\")\n",
    "        return None\n",
    "    \n",
    "    # 创建目标变量（基于status字段）\n",
    "    if 'status' in wellington_auckland_data.columns:\n",
    "        # 假设status为'sold'或类似表示已售出，我们将其作为正样本\n",
    "        wellington_auckland_data['target'] = wellington_auckland_data['status'].apply(\n",
    "            lambda x: 1 if pd.notna(x) and str(x).lower() in ['sold', 'sale', 'for sale', 'active'] else 0\n",
    "        )\n",
    "    else:\n",
    "        # 如果没有status字段，创建平衡的目标变量\n",
    "        print(\"⚠️ 没有找到status字段，创建平衡的训练数据\")\n",
    "        # 随机分配一半为已售出，一半为未售出\n",
    "        np.random.seed(42)\n",
    "        wellington_auckland_data['target'] = np.random.choice([0, 1], size=len(wellington_auckland_data), p=[0.4, 0.6])\n",
    "    \n",
    "    # 确保至少有两个类别\n",
    "    unique_targets = wellington_auckland_data['target'].unique()\n",
    "    if len(unique_targets) < 2:\n",
    "        print(\"⚠️ 目标变量只有一个类别，创建平衡数据\")\n",
    "        # 将一半数据改为另一个类别\n",
    "        half_idx = len(wellington_auckland_data) // 2\n",
    "        wellington_auckland_data.iloc[:half_idx, wellington_auckland_data.columns.get_loc('target')] = 0\n",
    "        wellington_auckland_data.iloc[half_idx:, wellington_auckland_data.columns.get_loc('target')] = 1\n",
    "    \n",
    "    # 标准化列名\n",
    "    column_mapping = {\n",
    "        'capital_value': 'capital_value',\n",
    "        'property_address': 'address',\n",
    "        'suburb': 'suburb',\n",
    "        'year_built': 'year_built',\n",
    "        'bedrooms': 'bedrooms',\n",
    "        'bathrooms': 'bathrooms',\n",
    "        'car_spaces': 'car_spaces',\n",
    "        'floor_size': 'floor_size',\n",
    "        'land_area': 'land_area',\n",
    "        'last_sold_price': 'last_sold_price',\n",
    "        'land_value': 'land_value',\n",
    "        'improvement_value': 'improvement_value',\n",
    "        'has_rental_history': 'has_rental_history',\n",
    "        'is_currently_rented': 'is_currently_rented'\n",
    "    }\n",
    "    \n",
    "    # 确保所有必要的列都存在\n",
    "    for col in ['suburb', 'year_built', 'bedrooms', 'bathrooms', 'car_spaces']:\n",
    "        if col not in wellington_auckland_data.columns:\n",
    "            print(f\"⚠️ 缺少关键列: {col}，将使用默认值\")\n",
    "            if col == 'suburb':\n",
    "                wellington_auckland_data[col] = 'Wellington'\n",
    "            elif col == 'year_built':\n",
    "                wellington_auckland_data[col] = 2000\n",
    "            elif col == 'bedrooms':\n",
    "                wellington_auckland_data[col] = 3\n",
    "            elif col == 'bathrooms':\n",
    "                wellington_auckland_data[col] = 1\n",
    "            elif col == 'car_spaces':\n",
    "                wellington_auckland_data[col] = 1\n",
    "    \n",
    "    print(f\"📊 目标变量分布: {wellington_auckland_data['target'].value_counts().to_dict()}\")\n",
    "    \n",
    "    return wellington_auckland_data\n",
    "\n",
    "def create_mock_training_data(n_samples=2000):\n",
    "    \"\"\"创建模拟训练数据\"\"\"\n",
    "    print(\"🔄 创建模拟训练数据...\")\n",
    "    np.random.seed(42)\n",
    "\n",
    "    suburbs = {\n",
    "        'Oriental Bay': {'base_price': 2000000, 'sale_rate': 0.90},\n",
    "        'Thorndon': {'base_price': 1500000, 'sale_rate': 0.85},\n",
    "        'Kelburn': {'base_price': 1300000, 'sale_rate': 0.80},\n",
    "        'Khandallah': {'base_price': 1400000, 'sale_rate': 0.82},\n",
    "        'Wellington Central': {'base_price': 1000000, 'sale_rate': 0.75},\n",
    "        'Mount Victoria': {'base_price': 1100000, 'sale_rate': 0.70},\n",
    "        'Te Aro': {'base_price': 900000, 'sale_rate': 0.65},\n",
    "        'Newtown': {'base_price': 700000, 'sale_rate': 0.40},\n",
    "        'Island Bay': {'base_price': 800000, 'sale_rate': 0.45},\n",
    "        'Karori': {'base_price': 950000, 'sale_rate': 0.55}\n",
    "    }\n",
    "\n",
    "    data = []\n",
    "    for i in range(n_samples):\n",
    "        suburb = np.random.choice(list(suburbs.keys()))\n",
    "        suburb_info = suburbs[suburb]\n",
    "\n",
    "        year_built = np.random.randint(1950, 2024)\n",
    "        bedrooms = np.random.choice([1, 2, 3, 4, 5, 6], p=[0.05, 0.2, 0.35, 0.3, 0.08, 0.02])\n",
    "        bathrooms = min(bedrooms, np.random.choice([1, 2, 3, 4], p=[0.25, 0.45, 0.25, 0.05]))\n",
    "        car_spaces = np.random.choice([0, 1, 2, 3], p=[0.15, 0.4, 0.35, 0.1])\n",
    "\n",
    "        floor_size = max(50, 60 + bedrooms * 25 + np.random.randint(-20, 30))\n",
    "\n",
    "        if suburb in ['Wellington Central', 'Te Aro']:\n",
    "            land_area = 0 if np.random.random() < 0.6 else np.random.randint(200, 400)\n",
    "        else:\n",
    "            land_area = np.random.randint(300, 1000)\n",
    "\n",
    "        # 价格计算\n",
    "        base_price = suburb_info['base_price']\n",
    "        property_age = 2024 - year_built\n",
    "\n",
    "        if property_age < 5:\n",
    "            age_factor = 1.2\n",
    "        elif property_age < 15:\n",
    "            age_factor = 1.1\n",
    "        elif property_age < 30:\n",
    "            age_factor = 1.0\n",
    "        elif property_age < 50:\n",
    "            age_factor = 0.9\n",
    "        else:\n",
    "            age_factor = 0.8\n",
    "\n",
    "        size_factor = 1 + (floor_size - 120) * 0.005\n",
    "        bedroom_factor = 1 + (bedrooms - 3) * 0.12\n",
    "\n",
    "        last_sold_price = int(base_price * age_factor * size_factor * bedroom_factor * np.random.uniform(0.85, 1.15))\n",
    "        capital_value = int(last_sold_price * np.random.uniform(0.95, 1.25))\n",
    "\n",
    "        land_value = int(capital_value * np.random.uniform(0.4, 0.7)) if land_area > 0 else 0\n",
    "        improvement_value = capital_value - land_value\n",
    "\n",
    "        has_rental_history = np.random.random() < 0.35\n",
    "        is_currently_rented = np.random.random() < 0.25 if has_rental_history else False\n",
    "\n",
    "        # 目标变量计算\n",
    "        sale_probability = suburb_info['sale_rate']\n",
    "\n",
    "        # 影响因子\n",
    "        if property_age < 5:\n",
    "            sale_probability += 0.35\n",
    "        elif property_age < 15:\n",
    "            sale_probability += 0.25\n",
    "        elif property_age > 60:\n",
    "            sale_probability -= 0.30\n",
    "\n",
    "        if last_sold_price > 2000000:\n",
    "            sale_probability += 0.30\n",
    "        elif last_sold_price < 600000:\n",
    "            sale_probability -= 0.25\n",
    "\n",
    "        if bedrooms >= 5:\n",
    "            sale_probability += 0.25\n",
    "        elif bedrooms <= 1:\n",
    "            sale_probability -= 0.20\n",
    "\n",
    "        if car_spaces >= 3:\n",
    "            sale_probability += 0.20\n",
    "        elif car_spaces == 0:\n",
    "            sale_probability -= 0.25\n",
    "\n",
    "        if is_currently_rented:\n",
    "            sale_probability -= 0.50\n",
    "        elif has_rental_history and not is_currently_rented:\n",
    "            sale_probability += 0.15\n",
    "\n",
    "        sale_probability = np.clip(sale_probability, 0.05, 0.95)\n",
    "\n",
    "        if sale_probability > 0.8:\n",
    "            target = 1 if np.random.random() < 0.95 else 0\n",
    "        elif sale_probability > 0.6:\n",
    "            target = 1 if np.random.random() < 0.85 else 0\n",
    "        elif sale_probability > 0.4:\n",
    "            target = 1 if np.random.random() < sale_probability else 0\n",
    "        else:\n",
    "            target = 1 if np.random.random() < 0.15 else 0\n",
    "\n",
    "        data.append({\n",
    "            'suburb': suburb, 'year_built': year_built, 'bedrooms': bedrooms,\n",
    "            'bathrooms': bathrooms, 'car_spaces': car_spaces, 'floor_size': floor_size,\n",
    "            'land_area': land_area, 'last_sold_price': last_sold_price,\n",
    "            'capital_value': capital_value, 'land_value': land_value,\n",
    "            'improvement_value': improvement_value, 'has_rental_history': has_rental_history,\n",
    "            'is_currently_rented': is_currently_rented, 'target': target\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"✅ 创建了 {len(df)} 条模拟训练数据\")\n",
    "    print(f\"📊 标签分布: {df['target'].value_counts().to_dict()}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# 获取训练数据\n",
    "training_data = get_training_data_from_real_estate()\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 数据探索和可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据探索
",
    "print(\"📊 数据基本信息:\")
",
    "print(f\"数据集大小: {training_data.shape}\")
",
    "print(f\"特征数量: {training_data.shape[1] - 1}\")
",
    "print(f\"目标变量分布: {training_data['target'].value_counts().to_dict()}\")
",
    "
",
    "# 检查缺失值
",
    "missing_values = training_data.isnull().sum()
",
    "print(\"\
📋 缺失值统计:\")
",
    "print(missing_values[missing_values > 0])
",
    "
",
    "# 数据类型
",
    "print(\"\
📋 数据类型:\")
",
    "print(training_data.dtypes)
",
    "
",
    "# 数值特征的统计描述
",
    "numeric_columns = training_data.select_dtypes(include=['int64', 'float64']).columns
",
    "print(\"\
📊 数值特征统计:\")
",
    "print(training_data[numeric_columns].describe())
",
    "
",
    "# 可视化
",
    "plt.figure(figsize=(12, 8))
",
    "
",
    "# 目标变量分布
",
    "plt.subplot(2, 2, 1)
",
    "sns.countplot(x='target', data=training_data)
",
    "plt.title('目标变量分布')
",
    "
",
    "# 房间数分布
",
    "plt.subplot(2, 2, 2)
",
    "sns.countplot(x='bedrooms', data=training_data, hue='target')
",
    "plt.title('卧室数量与销售状态关系')
",
    "
",
    "# 价格分布
",
    "plt.subplot(2, 2, 3)
",
    "if 'last_sold_price' in training_data.columns:
",
    "    sns.histplot(training_data['last_sold_price'], bins=20, kde=True)
",
    "    plt.title('最近售价分布')
",
    "    plt.ticklabel_format(style='plain', axis='x')
",
    "elif 'capital_value' in training_data.columns:
",
    "    sns.histplot(training_data['capital_value'], bins=20, kde=True)
",
    "    plt.title('资本价值分布')
",
    "    plt.ticklabel_format(style='plain', axis='x')
",
    "
",
    "# 建造年份分布
",
    "plt.subplot(2, 2, 4)
",
    "if 'year_built' in training_data.columns:
",
    "    sns.histplot(training_data['year_built'], bins=20, kde=True)
",
    "    plt.title('建造年份分布')
",
    "
",
    "plt.tight_layout()
",
    "plt.show()
",
    "
",
    "# 相关性矩阵
",
    "plt.figure(figsize=(12, 10))
",
    "numeric_data = training_data.select_dtypes(include=['int64', 'float64'])
",
    "correlation_matrix = numeric_data.corr()
",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
",
    "plt.title('特征相关性矩阵')
",
    "plt.tight_layout()
",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}