name: Weekly Supabase Database Backup

on:
  workflow_dispatch:  # Allow manual trigger
  schedule:
    - cron: "0 2 * * 0"  # Run every Sunday at 2:00 AM UTC (weekly automatic backup)

concurrency:
  group: backup-supabase
  cancel-in-progress: false

jobs:
  backup:
    runs-on: ubuntu-latest
    timeout-minutes: 330  # 5.5 hours timeout for large databases

    env:
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
      DATABASE_URL: ${{ secrets.DATABASE_URL }}
      SUPABASE_DB_PASSWORD: ${{ secrets.SUPABASE_DB_PASSWORD }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install PostgreSQL client
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Create backup directory
        run: mkdir -p database/backup

      - name: Setup DATABASE_URL if not provided
        run: |
          if [ -z "$DATABASE_URL" ]; then
            # Extract project reference from SUPABASE_URL
            PROJECT_REF=$(echo $SUPABASE_URL | sed 's/https:\/\/\([^.]*\).supabase.co/\1/')
            
            # Construct DATABASE_URL for direct database connection
            # Format: postgresql://postgres:[password]@db.[project-ref].supabase.co:5432/postgres
            if [ -n "$SUPABASE_DB_PASSWORD" ]; then
              export DATABASE_URL="postgresql://postgres:${SUPABASE_DB_PASSWORD}@db.${PROJECT_REF}.supabase.co:5432/postgres"
              echo "DATABASE_URL constructed from Supabase project info"
            else
              echo "Warning: Neither DATABASE_URL nor SUPABASE_DB_PASSWORD is set"
              echo "pg_dump backup will be skipped"
            fi
          else
            echo "DATABASE_URL is already set"
          fi

      - name: Check if backup is already running
=======
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          python -c "
          import os
          from supabase import create_client, Client
          
          url = os.environ.get('SUPABASE_URL')
          key = os.environ.get('SUPABASE_KEY')
          supabase: Client = create_client(url, key)
          
          try:
              result = supabase.table('scraping_progress').select('id').eq('id', 7).eq('status', 'running').execute()
              if result.data:
                  print('Database backup is already running. Exiting...')
                  exit(1)
              print('No running database backup found. Proceeding...')
          except:
              print('Could not check backup status. Proceeding...')
          "

      - name: Run complete database backup
        run: python database/backup_supabase.py

      - name: Upload backup as artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: weekly-supabase-backup-${{ github.run_number }}
          path: database/backup/
          retention-days: 90  # Keep weekly backups for 3 months

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: backup-logs-${{ github.run_number }}
          path: |
            *.log
          retention-days: 30  # Keep logs for 1 month