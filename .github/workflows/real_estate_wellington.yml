name: Scrape RealEstate Wellington

on:
  workflow_dispatch:
  schedule:
    - cron: "0 */6 * * *" # Run every 6 hours to allow completion

concurrency:
  group: scrape-realestate-wellington
  cancel-in-progress: true

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 330

    env:
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
      REALESTATE_URL: https://www.realestate.co.nz/residential/sale
      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      GITHUB_REPOSITORY: ${{ github.repository }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          playwright install

      - name: Force reset expired status and check running status
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          python -c "
          import os
          from datetime import datetime, timezone, timedelta
          from supabase import create_client, Client
          
          url = os.environ.get('SUPABASE_URL')
          key = os.environ.get('SUPABASE_KEY')
          supabase: Client = create_client(url, key)
          
          # Check current status
          result = supabase.table('scraping_progress').select('*').eq('id', 3).execute()
          if not result.data:
              print('No scraping progress record found')
              exit(1)
          
          record = result.data[0]
          status = record.get('status')
          updated_at = record.get('updated_at')
          
          print(f'Current status: {status}')
          print(f'Last updated: {updated_at}')
          
          # If status is running, check if it's expired (more than 30 minutes old)
          if status == 'running' and updated_at:
              from dateutil import parser
              last_update = parser.parse(updated_at)
              now = datetime.now(timezone.utc)
              time_diff = now - last_update
              
              # Use 30 minutes as expiration time to match the script's expected behavior
              if time_diff > timedelta(minutes=30):
                  print(f'Status has been running for {time_diff}, resetting to idle')
                  supabase.table('scraping_progress').update({
                      'status': 'idle',
                      'updated_at': 'now()'
                  }).eq('id', 3).execute()
                  print('Expired status reset to idle')
              else:
                  print(f'Wellington scraping is currently running (started {time_diff} ago). Exiting...')
                  exit(1)
          
          print('Ready to start scraping')
          "

      - name: Set status to running
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          python -c "
          import os
          from supabase import create_client, Client
          
          url = os.environ.get('SUPABASE_URL')
          key = os.environ.get('SUPABASE_KEY')
          supabase: Client = create_client(url, key)
          
          supabase.table('scraping_progress').update({
              'status': 'running',
              'updated_at': 'now()'
          }).eq('id', 3).execute()
          print('Status set to running')
          "

      - name: Run scraper
        run: python real_estate_wellington.py

      - name: Reset status to idle on completion or failure
        if: always()
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          python -c "
          import os
          from supabase import create_client, Client
          from datetime import datetime, timezone, timedelta
          from dateutil import parser
          
          url = os.environ.get('SUPABASE_URL')
          key = os.environ.get('SUPABASE_KEY')
          supabase: Client = create_client(url, key)
          
          try:
              # Check current status before resetting
              result = supabase.table('scraping_progress').select('status, updated_at').eq('id', 3).execute()
              if result.data:
                  record = result.data[0]
                  status = record.get('status')
                  updated_at = record.get('updated_at')
                  
                  # If status is already 'complete', don't reset it to 'idle'
                  if status == 'complete':
                      print('Task is already marked as complete. Not resetting status.')
                      exit(0)
                  
                  # If status is 'running' but updated recently, keep it as is
                  if status == 'running' and updated_at:
                      last_update = parser.parse(updated_at)
                      now = datetime.now(timezone.utc)
                      time_diff = now - last_update
                      
                      # If updated within last 10 minutes, assume it's still running
                      if time_diff <= timedelta(minutes=10):
                          print(f'Task is still running (updated {time_diff} ago). Not resetting status.')
                          exit(0)
              
              # Reset status to idle for all other cases
              supabase.table('scraping_progress').update({
                  'status': 'idle',
                  'updated_at': 'now()'
              }).eq('id', 3).execute()
              print('Status reset to idle successfully')
          except Exception as e:
              print(f'Failed to reset status: {e}')
          "

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: wellington-logs-${{ github.run_number }}
          path: |
            *.log
          retention-days: 7